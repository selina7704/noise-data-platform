import logging
import io
import numpy as np
import librosa
import tensorflow as tf
from fastapi import FastAPI, File, UploadFile

app = FastAPI()
logging.basicConfig(level=logging.DEBUG)

# ğŸ”¹ ëª¨ë¸ ë¡œë“œ
def load_model():
    """ ResNet ëª¨ë¸ ë¡œë“œ """
    try:
        model = tf.keras.models.load_model("resnet_model_modified_v6.h5")
        logging.info("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        return model
    except Exception as e:
        logging.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None

resnet_model = load_model()

# ğŸ”¹ ì†ŒìŒ ìœ í˜•ë³„ ê¸°ì¤€ ë°ì‹œë²¨ ì„¤ì •
SPL_REFERENCE = 20e-6  # 0dB ê¸°ì¤€ ìŒì••
DB_REFERENCE = {
    "ì°¨ëŸ‰ ê²½ì ": 100,
    "ì´ë¥œì°¨ ê²½ì ": 100,
    "ì‚¬ì´ë Œ": 110,
    "ì°¨ëŸ‰ ì£¼í–‰ìŒ": 90,
    "ì´ë¥œì°¨ ì£¼í–‰ìŒ": 95,
    "ê¸°íƒ€ ì†ŒìŒ": 85,
}

NOISE_LABELS = ["ì´ë¥œì°¨ ê²½ì ", "ì´ë¥œì°¨ ì£¼í–‰ìŒ", "ì°¨ëŸ‰ ê²½ì ", "ì‚¬ì´ë Œ", "ì°¨ëŸ‰ ì£¼í–‰ìŒ", "ê¸°íƒ€ ì†ŒìŒ"]

# ğŸ”¹ ê³ ì£¼íŒŒ ì†ŒìŒ ëª©ë¡ (Peak SPL ì‚¬ìš©)
HIGH_FREQ_SOUNDS = ["ì‚¬ì´ë Œ", "ì°¨ëŸ‰ ê²½ì ", "ì´ë¥œì°¨ ê²½ì "]

# ğŸ”¹ MFCC íŠ¹ì§• ì¶”ì¶œ
def extract_mfcc(file_bytes, n_mfcc=50):
    """ ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ MFCC íŠ¹ì§• ì¶”ì¶œ """
    y, sr = librosa.load(io.BytesIO(file_bytes), sr=None)
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)
    return np.mean(mfccs, axis=1).reshape(1, -1)

# ğŸ”¹ ì†ŒìŒ ë¶„ë¥˜ ëª¨ë¸ ì˜ˆì¸¡
def predict_label(features, threshold=0.8):
    if resnet_model is None:
        logging.error("âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŒ!")
        return "ê¸°íƒ€ ì†ŒìŒ"

    predictions = resnet_model.predict(features)
    max_prob = np.max(predictions)
    predicted_index = np.argmax(predictions)

    return NOISE_LABELS[predicted_index] if max_prob >= threshold else "ê¸°íƒ€ ì†ŒìŒ"

# ğŸ”¹ ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜ (ì†ŒìŒ ìœ í˜•ë³„ Peak SPL vs RMS SPL ì ìš©)
def estimate_distance(spl_peak, spl_rms, predicted_label):
    """ ì†ŒìŒ ìœ í˜•ë³„ ê±°ë¦¬ ê³„ì‚° (Peak vs RMS ì ìš©) """
    db_ref = DB_REFERENCE.get(predicted_label, 85)

    # ğŸ”¥ Peak SPLì„ ì‚¬ìš©í• ì§€, RMS SPLì„ ì‚¬ìš©í• ì§€ ê²°ì •
    if predicted_label in HIGH_FREQ_SOUNDS:
        spl_used = spl_peak
    else:
        spl_used = spl_rms

    estimated_distance = 1 * (10 ** ((db_ref - spl_used) / 20))
    return "50ë¯¸í„° ì´ìƒ" if estimated_distance > 50 else round(estimated_distance, 1)

# ğŸ”¹ ë°©í–¥ íŒë³„ í•¨ìˆ˜
def estimate_direction(y, predicted_label):
    """ ì†ŒìŒ ìœ í˜•ì— ë”°ë¼ ê³ ì£¼íŒŒ/ì €ì£¼íŒŒ ì°¨ì´ë¥¼ ë°˜ì˜í•œ ë°©í–¥ íŒë³„ """
    if len(y.shape) == 1:
        return "ì•Œ ìˆ˜ ì—†ìŒ"

    left_channel, right_channel = y[0], y[1]
    rms_left = np.sqrt(np.mean(left_channel ** 2))
    rms_right = np.sqrt(np.mean(right_channel ** 2))

    spl_left = 20 * np.log10(rms_left / SPL_REFERENCE + 1e-6)
    spl_right = 20 * np.log10(rms_right / SPL_REFERENCE + 1e-6)

    db_diff = spl_left - spl_right
    threshold = 2 if predicted_label in HIGH_FREQ_SOUNDS else 1  

    if abs(db_diff) < threshold:
        return "ì¤‘ì•™"
    elif db_diff > threshold:
        return "ì™¼ìª½"
    return "ì˜¤ë¥¸ìª½"

# ğŸ”¹ ì˜¤ë””ì˜¤ ë¶„ì„ (ë°ì‹œë²¨, ê±°ë¦¬, ë°©í–¥ í¬í•¨)
def analyze_audio(file_bytes, predicted_label):
    """ ì˜¤ë””ì˜¤ ë¶„ì„ (ë°ì‹œë²¨, ê±°ë¦¬, ë°©í–¥ í¬í•¨) """
    y, sr = librosa.load(io.BytesIO(file_bytes), sr=None, mono=False)
    if y is None or len(y) == 0:
        return {"error": "ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì§€ ëª»í•¨"}

    is_stereo = len(y.shape) == 2 and y.shape[0] == 2

    # ğŸ”¹ RMS & Peak SPL ê³„ì‚°
    rms_total = np.sqrt(np.mean(y ** 2))
    rms_spl = 20 * np.log10(rms_total / SPL_REFERENCE + 1e-6)
    peak_amplitude = np.max(np.abs(y))
    peak_spl = 20 * np.log10(peak_amplitude / SPL_REFERENCE + 1e-6)

    # ğŸ”¹ ê±°ë¦¬ ì˜ˆì¸¡ (ì†ŒìŒ ìœ í˜•ë³„ SPL ì„ íƒ)
    estimated_distance = estimate_distance(peak_spl, rms_spl, predicted_label)

    # ğŸ”¹ ë°©í–¥ íŒë³„
    direction = estimate_direction(y, predicted_label) if is_stereo else "ì•Œ ìˆ˜ ì—†ìŒ"

    return {
        "prediction": predicted_label,
        "spl_peak": round(peak_spl, 2),
        "spl_rms": round(rms_spl, 2),
        "estimated_distance": estimated_distance,
        "direction": direction
    }

# ğŸ”¹ FastAPI ì—”ë“œí¬ì¸íŠ¸
@app.post("/predict/")
async def predict(file: UploadFile = File(...)):
    """ WAV íŒŒì¼ ë¶„ì„ API """
    file_bytes = await file.read()
    features = extract_mfcc(file_bytes)
    predicted_label = predict_label(features)
    result = analyze_audio(file_bytes, predicted_label)
    return result


















