import os
import librosa
import numpy as np
import tensorflow as tf
import io
import logging
from fastapi import FastAPI, File, UploadFile, WebSocket
from tensorflow.keras.models import load_model


app = FastAPI()

# GPU ë¹„í™œì„±í™”
tf.config.set_visible_devices([], 'GPU')

# ëª¨ë¸ ë¡œë“œ
model = load_model('../model/resnet_model_modified_v6.h5')
print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: resnet_model_modified_v6.h5")

# ê³ ì •ê°’ ì„¤ì •
ENERGY_THRESHOLD = -1.8595
MEAN_ENERGY_IND = -15.5199
STD_ENERGY_IND = 8.8151
CONFIDENCE_THRESHOLD = 0.9
TEMPERATURE = 1.0

# ë¼ë²¨ ì •ì˜
final_labels = ['ì´ë¥œì°¨ê²½ì ', 'ì´ë¥œì°¨ì£¼í–‰ìŒ', 'ì°¨ëŸ‰ê²½ì ', 'ì°¨ëŸ‰ì‚¬ì´ë Œ', 'ì°¨ëŸ‰ì£¼í–‰ìŒ', 'ê¸°íƒ€ì†ŒìŒ']
label_to_code = {label: i for i, label in enumerate(final_labels)}
index_to_label = {v: k for k, v in label_to_code.items()}
unknown_label_index = label_to_code['ê¸°íƒ€ì†ŒìŒ']

# ì†ŒìŒ ìœ í˜•ë³„ ë°ì‹œë²¨ ê¸°ì¤€
SPL_REFERENCE = 20e-6
DB_REFERENCE = {
    "ì°¨ëŸ‰ ê²½ì ": 100, "ì´ë¥œì°¨ ê²½ì ": 100, "ì‚¬ì´ë Œ": 100,
    "ì°¨ëŸ‰ ì£¼í–‰ìŒ": 90, "ì´ë¥œì°¨ ì£¼í–‰ìŒ": 90, "ê¸°íƒ€ ì†ŒìŒ": 85,
}

# Energy Score ê³„ì‚°
def compute_energy(logits, T=TEMPERATURE):
    exp_vals = np.exp(logits / T)
    sum_exp = np.sum(exp_vals, axis=1) + 1e-9
    return -T * np.log(sum_exp)

# ğŸ”¹ ê³ ì£¼íŒŒ ì†ŒìŒ ëª©ë¡ (Peak SPL ì‚¬ìš©)
HIGH_FREQ_SOUNDS = ["ì‚¬ì´ë Œ", "ì°¨ëŸ‰ ê²½ì ", "ì´ë¥œì°¨ ê²½ì "]

# ğŸ”¹ ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜ (ì†ŒìŒ ìœ í˜•ë³„ Peak SPL vs RMS SPL ì ìš©)
def estimate_distance(spl_peak, spl_rms, predicted_label):
    """ ì†ŒìŒ ìœ í˜•ë³„ ê±°ë¦¬ ê³„ì‚° (Peak vs RMS ì ìš©) """
    db_ref = DB_REFERENCE.get(predicted_label, 85)

    # ğŸ”¥ Peak SPLì„ ì‚¬ìš©í• ì§€, RMS SPLì„ ì‚¬ìš©í• ì§€ ê²°ì •
    if predicted_label in HIGH_FREQ_SOUNDS:
        spl_used = spl_peak
    else:
        spl_used = spl_rms

    estimated_distance = 1 * (10 ** ((db_ref - spl_used) / 20))
    return "50ë¯¸í„° ì´ìƒ" if estimated_distance > 50 else round(estimated_distance, 1)

# ğŸ”¹ ë°©í–¥ íŒë³„ í•¨ìˆ˜
def estimate_direction(y, predicted_label):
    """ ì†ŒìŒ ìœ í˜•ì— ë”°ë¼ ê³ ì£¼íŒŒ/ì €ì£¼íŒŒ ì°¨ì´ë¥¼ ë°˜ì˜í•œ ë°©í–¥ íŒë³„ """
    if len(y.shape) == 1:
        return "ì•Œ ìˆ˜ ì—†ìŒ"

    left_channel, right_channel = y[0], y[1]
    rms_left = np.sqrt(np.mean(left_channel ** 2))
    rms_right = np.sqrt(np.mean(right_channel ** 2))

    spl_left = 20 * np.log10(rms_left / SPL_REFERENCE + 1e-6)
    spl_right = 20 * np.log10(rms_right / SPL_REFERENCE + 1e-6)

    db_diff = spl_left - spl_right
    threshold = 2 if predicted_label in HIGH_FREQ_SOUNDS else 1  

    if abs(db_diff) < threshold:
        return "ì¤‘ì•™"
    elif db_diff > threshold:
        return "ì™¼ìª½"
    return "ì˜¤ë¥¸ìª½"

# ğŸ”¹ ì˜¤ë””ì˜¤ ë¶„ì„ (ë°ì‹œë²¨, ê±°ë¦¬, ë°©í–¥ í¬í•¨)
def analyze_audio(file_bytes, predicted_label):
    """ ì˜¤ë””ì˜¤ ë¶„ì„ (ë°ì‹œë²¨, ê±°ë¦¬, ë°©í–¥ í¬í•¨) """
    y, sr = librosa.load(io.BytesIO(file_bytes), sr=None, mono=False)
    if y is None or len(y) == 0:
        return {"error": "ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì§€ ëª»í•¨"}

    is_stereo = len(y.shape) == 2 and y.shape[0] == 2

    # ğŸ”¹ RMS & Peak SPL ê³„ì‚°
    rms_total = np.sqrt(np.mean(y ** 2))
    rms_spl = 20 * np.log10(rms_total / SPL_REFERENCE + 1e-6)
    peak_amplitude = np.max(np.abs(y))
    peak_spl = 20 * np.log10(peak_amplitude / SPL_REFERENCE + 1e-6)

    # ë¬´ìŒ ê°ì§€ (RMS ê°’ì´ ë„ˆë¬´ ë‚®ìœ¼ë©´ ë¬´ìŒìœ¼ë¡œ ì²˜ë¦¬)
    if rms_spl < 10:
        return {
            "prediction": "ë¬´ìŒ ê°ì§€",
            "spl_peak": round(peak_spl, 2),
            "spl_rms": round(rms_spl, 2),
            "estimated_distance": "ì•Œ ìˆ˜ ì—†ìŒ",
            "direction": "ì•Œ ìˆ˜ ì—†ìŒ"
        }
        
    estimated_distance = estimate_distance(peak_spl, rms_spl, predicted_label) #ê±°ë¦¬ ì˜ˆì¸¡
    direction = estimate_direction(y, predicted_label) if is_stereo else "ì•Œ ìˆ˜ ì—†ìŒ" #ë°©í–¥ íŒë³„ 

    return {
        "prediction": predicted_label,
        "spl_peak": round(peak_spl, 2),
        "spl_rms": round(rms_spl, 2),
        "estimated_distance": estimated_distance,
        "direction": direction
    }



# # ì˜¤ë””ì˜¤ ë¶„ì„ í•¨ìˆ˜
# def analyze_audio(file_bytes, predicted_label):
#     try:
#         y, sr = librosa.load(io.BytesIO(file_bytes), sr=None, mono=False)
        
#         if y is None or len(y) == 0:
#             logging.error("âŒ librosaê°€ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì§€ ëª»í•¨!")
#             return {"error": "librosaê°€ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì§€ ëª»í•¨"}
        
#         is_stereo = len(y.shape) == 2 and y.shape[0] == 2

#         if is_stereo:
#             left_channel = y[0]
#             right_channel = y[1]
#             rms_total = np.sqrt(np.mean((left_channel + right_channel) ** 2)) / 2
#         else:
#             rms_total = np.sqrt(np.mean(y ** 2))

#         if rms_total == 0:
#             logging.error("âŒ RMS ê³„ì‚° ì¤‘ ê°’ì´ 0ì´ ë¨!")
#             return {"error": "RMS ê³„ì‚° ì˜¤ë¥˜"}

#         rms_spl = 20 * np.log10(rms_total / SPL_REFERENCE + 1e-6)
#         peak_amplitude = np.max(np.abs(y))
#         peak_spl = 20 * np.log10(peak_amplitude / SPL_REFERENCE + 1e-6)

#         spl_used = peak_spl if predicted_label in ["ì°¨ëŸ‰ ê²½ì ", "ì´ë¥œì°¨ ê²½ì ", "ì‚¬ì´ë Œ"] else rms_spl
#         db_ref = DB_REFERENCE.get(predicted_label, 85)
#         estimated_distance = round(1 * (10 ** ((db_ref - spl_used) / 20)), 2)
#         estimated_distance = max(0.1, min(estimated_distance, 1000))

#         direction = "ì•Œ ìˆ˜ ì—†ìŒ"
#         if is_stereo:
#             rms_left = np.sqrt(np.mean(left_channel ** 2))
#             rms_right = np.sqrt(np.mean(right_channel ** 2))
#             spl_left = 20 * np.log10(rms_left / SPL_REFERENCE + 1e-6)
#             spl_right = 20 * np.log10(rms_right / SPL_REFERENCE + 1e-6)
#             db_difference = spl_left - spl_right
#             if abs(db_difference) < 1.5:
#                 direction = "ì¤‘ì•™"
#             elif 1.5 <= abs(db_difference) < 3:
#                 direction = "ì•½ê°„ ì™¼ìª½" if db_difference > 0 else "ì•½ê°„ ì˜¤ë¥¸ìª½"
#             else:
#                 direction = "ì™¼ìª½" if db_difference > 0 else "ì˜¤ë¥¸ìª½"
        
#         return {
#             "prediction": predicted_label,
#             "spl": round(spl_used, 2),
#             "estimated_distance": estimated_distance,
#             "direction": direction,
#         }
#     except Exception as e:
#         logging.error(f"âŒ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
#         return {"error": str(e)}

# ëª¨ë¸ ì˜ˆì¸¡ (ê³ ì •ê°’ ì ìš©)
@app.post("/predict/")
async def predict(file: UploadFile = File(...)):
    file_bytes = await file.read()
    print(f"íŒŒì¼ ì´ë¦„: {file.filename}")

    audio_bytes = io.BytesIO(file_bytes)
    audio_librosa, sr_librosa = librosa.load(audio_bytes, sr=None)
    
    if len(audio_librosa) == 0:
        return {"error": "ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŒ"}

    print("librosaë¡œ ì²˜ë¦¬í•œ ìƒ˜í”Œë§ ë ˆì´íŠ¸:", sr_librosa)
    
    mfccs = librosa.feature.mfcc(y=audio_librosa, sr=sr_librosa, n_mfcc=50)
    features = np.mean(mfccs, axis=1).astype(float)
    print(features)

    X = features.reshape(1, 50, 1)
    logits = model.predict(X, verbose=0)
    energy_score = compute_energy(logits)[0]
    softmax_probs = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)
    max_prob = np.max(softmax_probs, axis=1)[0]
    basic_pred = np.argmax(softmax_probs, axis=1)[0]
    z_score = (energy_score - MEAN_ENERGY_IND) / STD_ENERGY_IND

    if max_prob < CONFIDENCE_THRESHOLD and energy_score > ENERGY_THRESHOLD and z_score > 1.5:
        predicted_label = unknown_label_index
    else:
        predicted_label = basic_pred

    detected_noise = index_to_label[predicted_label]
    print(f"ì˜ˆì¸¡ëœ ì†ŒìŒ ìœ í˜•: {detected_noise}")

    result = analyze_audio(file_bytes, detected_noise)
    result["confidence"] = float(round(max_prob, 4))
    print(result)
    return result

@app.websocket("/ws/audio")
async def audio_stream(websocket: WebSocket):
    await websocket.accept()
    try:
        while True:
            audio_data = await websocket.receive_bytes()
            print("Received audio data")
            await websocket.send_text("Audio data received")
    except Exception as e:
        print(f"Error: {e}")
    finally:
        await websocket.close()