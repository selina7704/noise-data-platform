{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5ed6a62",
   "metadata": {},
   "source": [
    "# WAV_motorcycle_MySQL_ì ì¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ec7462",
   "metadata": {},
   "source": [
    "## 0. Spark Session ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0aa6070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# MySQL JDBC ë“œë¼ì´ë²„ ê²½ë¡œ (ì••ì¶• í‘¼ ë“œë¼ì´ë²„ JAR íŒŒì¼ ê²½ë¡œ)\n",
    "mysql_driver_path = \"/home/ubuntu/mysql-connector-j-9.2.0/mysql-connector-j-9.2.0.jar\"\n",
    "\n",
    "\n",
    "# SparkSession ìƒì„±\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WAV_motor\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://localhost:9000\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .config(\"spark.jars\", mysql_driver_path) \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b4cf36",
   "metadata": {},
   "source": [
    "## 1. wav_motor_horn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "738987d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import io\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
    "\n",
    "# HDFSì—ì„œ ëª¨ë“  WAV íŒŒì¼ ì½ê¸°\n",
    "hdfs_dir = \"hdfs://localhost:9000/shared_data/raw_data/2.Motorcycle/4.horn_of_motorcycle\"\n",
    "binary_df = spark.read.format(\"binaryFile\").load(hdfs_dir)\n",
    "\n",
    "# ğŸ”¹ UDF (User Defined Function) ì •ì˜: WAV â†’ MFCC ë³€í™˜\n",
    "def extract_mfcc(binary_data):\n",
    "    try:\n",
    "        audio_bytes = io.BytesIO(binary_data)  # ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ íŒŒì¼ë¡œ ë³€í™˜\n",
    "        sr, audio = wavfile.read(audio_bytes)  # scipyë¡œ ìƒ˜í”Œë§ ë ˆì´íŠ¸ í™•ì¸\n",
    "        audio_librosa, sr_librosa = librosa.load(audio_bytes, sr=None)  # librosaë¡œ ë¦¬ìƒ˜í”Œë§\n",
    "        mfcc = librosa.feature.mfcc(y=audio_librosa, sr=sr_librosa, n_mfcc=13)  # MFCC ì¶”ì¶œ\n",
    "        mfcc_mean = np.mean(mfcc, axis=1).astype(float)  # í‰ê·  ê³„ì‚°\n",
    "        return mfcc_mean.tolist()  # ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n",
    "    except Exception as e:\n",
    "        return None  # ì—ëŸ¬ ë°œìƒ ì‹œ None ë°˜í™˜\n",
    "\n",
    "# UDF ë“±ë¡\n",
    "mfcc_udf = udf(extract_mfcc, ArrayType(FloatType()))\n",
    "\n",
    "# ğŸ”¹ íŒŒì¼ ì´ë¦„ ì¶”ì¶œ UDF ì •ì˜\n",
    "def extract_filename(path):\n",
    "    return os.path.basename(path)\n",
    "\n",
    "filename_udf = udf(extract_filename, StringType())\n",
    "\n",
    "# ğŸ”¹ ë³€í™˜ ì ìš©\n",
    "df_mfcc = binary_df \\\n",
    "    .withColumn(\"fileName\", filename_udf(binary_df[\"path\"])) \\\n",
    "    .withColumn(\"mfcc_features\", mfcc_udf(binary_df[\"content\"]))\n",
    "\n",
    "# ğŸ”¹ ë°°ì—´ ë°ì´í„°ë¥¼ ê°œë³„ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜\n",
    "mfcc_columns = [f\"mfcc_{i+1}\" for i in range(13)]\n",
    "for i in range(13):\n",
    "    df_mfcc = df_mfcc.withColumn(mfcc_columns[i], df_mfcc[\"mfcc_features\"][i])\n",
    "\n",
    "# ğŸ”¹ ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì •ë¦¬\n",
    "df_mfcc = df_mfcc.select([\"fileName\"] + mfcc_columns)\n",
    "\n",
    "# ğŸ”¹ ê²°ê³¼ ì €ì¥ (HDFS)\n",
    "# output_path = \"hdfs://localhost:9000/shared_data/mfcc_features/\"\n",
    "# df_mfcc.write.csv(output_path, header=True, mode=\"overwrite\")\n",
    "\n",
    "# print(f\"âœ… MFCC ë°ì´í„°ê°€ HDFSì— ì €ì¥ë¨: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a498916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4560"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mfcc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d9df333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„°ê°€ MySQLë¡œ ì„±ê³µì ìœ¼ë¡œ ì ì¬ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "df_mfcc.createOrReplaceTempView(\"wav_motor_horn\")\n",
    "\n",
    "# SQL ì¿¼ë¦¬ ì‹¤í–‰í•˜ì—¬ ë°ì´í„° ì¶”ì¶œ\n",
    "df_mfcc = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM wav_motor_horn\n",
    "\"\"\")\n",
    "\n",
    "# MySQLì—°ê²°\n",
    "mysql_url = \"jdbc:mysql://15.168.145.74:3306/my_db?useUnicode=true&characterEncoding=UTF-8\"\n",
    "mysql_properties = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"root\",\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "# MySQLë¡œ DataFrame ì ì¬ (ì¿¼ë¦¬ ê²°ê³¼ê°€ Noneì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)\n",
    "if df_mfcc is not None:\n",
    "    df_mfcc.write.jdbc(url=mysql_url, table=\"wav_motorcycle_horn_data\", mode=\"overwrite\", properties=mysql_properties)\n",
    "    print(\"ë°ì´í„°ê°€ MySQLë¡œ ì„±ê³µì ìœ¼ë¡œ ì ì¬ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"ì¿¼ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ì¶”ì¶œì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116729f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb7f84b3",
   "metadata": {},
   "source": [
    "## 2. wav_motor_driving_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8d2392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import io\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
    "\n",
    "# HDFSì—ì„œ ëª¨ë“  WAV íŒŒì¼ ì½ê¸°\n",
    "hdfs_dir = \"hdfs://localhost:9000/shared_data/raw_data/2.Motorcycle/5.driving_sound_of_motorcycle\"\n",
    "binary_df = spark.read.format(\"binaryFile\").load(hdfs_dir)\n",
    "\n",
    "# ğŸ”¹ UDF (User Defined Function) ì •ì˜: WAV â†’ MFCC ë³€í™˜\n",
    "def extract_mfcc(binary_data):\n",
    "    try:\n",
    "        audio_bytes = io.BytesIO(binary_data)  # ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ íŒŒì¼ë¡œ ë³€í™˜\n",
    "        sr, audio = wavfile.read(audio_bytes)  # scipyë¡œ ìƒ˜í”Œë§ ë ˆì´íŠ¸ í™•ì¸\n",
    "        audio_librosa, sr_librosa = librosa.load(audio_bytes, sr=None)  # librosaë¡œ ë¦¬ìƒ˜í”Œë§\n",
    "        mfcc = librosa.feature.mfcc(y=audio_librosa, sr=sr_librosa, n_mfcc=13)  # MFCC ì¶”ì¶œ\n",
    "        mfcc_mean = np.mean(mfcc, axis=1).astype(float)  # í‰ê·  ê³„ì‚°\n",
    "        return mfcc_mean.tolist()  # ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n",
    "    except Exception as e:\n",
    "        return None  # ì—ëŸ¬ ë°œìƒ ì‹œ None ë°˜í™˜\n",
    "\n",
    "# UDF ë“±ë¡\n",
    "mfcc_udf = udf(extract_mfcc, ArrayType(FloatType()))\n",
    "\n",
    "# ğŸ”¹ íŒŒì¼ ì´ë¦„ ì¶”ì¶œ UDF ì •ì˜\n",
    "def extract_filename(path):\n",
    "    return os.path.basename(path)\n",
    "\n",
    "filename_udf = udf(extract_filename, StringType())\n",
    "\n",
    "# ğŸ”¹ ë³€í™˜ ì ìš©\n",
    "df_mfcc = binary_df \\\n",
    "    .withColumn(\"fileName\", filename_udf(binary_df[\"path\"])) \\\n",
    "    .withColumn(\"mfcc_features\", mfcc_udf(binary_df[\"content\"]))\n",
    "\n",
    "# ğŸ”¹ ë°°ì—´ ë°ì´í„°ë¥¼ ê°œë³„ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜\n",
    "mfcc_columns = [f\"mfcc_{i+1}\" for i in range(13)]\n",
    "for i in range(13):\n",
    "    df_mfcc = df_mfcc.withColumn(mfcc_columns[i], df_mfcc[\"mfcc_features\"][i])\n",
    "\n",
    "# ğŸ”¹ ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì •ë¦¬\n",
    "df_mfcc = df_mfcc.select([\"fileName\"] + mfcc_columns)\n",
    "\n",
    "# ğŸ”¹ ê²°ê³¼ ì €ì¥ (HDFS)\n",
    "# output_path = \"hdfs://localhost:9000/shared_data/mfcc_features/\"\n",
    "# df_mfcc.write.csv(output_path, header=True, mode=\"overwrite\")\n",
    "\n",
    "# print(f\"âœ… MFCC ë°ì´í„°ê°€ HDFSì— ì €ì¥ë¨: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "517239d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4735"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mfcc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86c2a8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„°ê°€ MySQLë¡œ ì„±ê³µì ìœ¼ë¡œ ì ì¬ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "df_mfcc.createOrReplaceTempView(\"wav_motor_driving\")\n",
    "\n",
    "# SQL ì¿¼ë¦¬ ì‹¤í–‰í•˜ì—¬ ë°ì´í„° ì¶”ì¶œ\n",
    "df_mfcc = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM wav_motor_driving\n",
    "\"\"\")\n",
    "\n",
    "# MySQLì—°ê²°\n",
    "mysql_url = \"jdbc:mysql://15.168.145.74:3306/my_db?useUnicode=true&characterEncoding=UTF-8\"\n",
    "mysql_properties = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"root\",\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "# MySQLë¡œ DataFrame ì ì¬ (ì¿¼ë¦¬ ê²°ê³¼ê°€ Noneì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)\n",
    "if df_mfcc is not None:\n",
    "    df_mfcc.write.jdbc(url=mysql_url, table=\"wav_motorcycle_driving_data\", mode=\"overwrite\", properties=mysql_properties)\n",
    "    print(\"ë°ì´í„°ê°€ MySQLë¡œ ì„±ê³µì ìœ¼ë¡œ ì ì¬ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"ì¿¼ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ì¶”ì¶œì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70aec751",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(ml_env_python3.6)",
   "language": "python",
   "name": "ml_env_python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
