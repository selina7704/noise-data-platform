{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5ed6a62",
   "metadata": {},
   "source": [
    "# WAV_motorcycle_MySQL_ì ì¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ec7462",
   "metadata": {},
   "source": [
    "## 0. Spark Session ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0aa6070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import config\n",
    "from config import DB_CONFIG, HDFS_CONFIG\n",
    "\n",
    "# MySQL JDBC ë“œë¼ì´ë²„ ê²½ë¡œ\n",
    "mysql_driver_path = config.MYSQL_JDBC\n",
    "\n",
    "# SparkSession ìƒì„±\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WAV_motor\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", HDFS_CONFIG[\"defaultFS\"]) \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .config(\"spark.jars\", mysql_driver_path) \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b4cf36",
   "metadata": {},
   "source": [
    "## 1. wav_motor_horn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "738987d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import io\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
    "\n",
    "# HDFSì—ì„œ ëª¨ë“  WAV íŒŒì¼ ì½ê¸°\n",
    "hdfs_dir = f\"{config.HDFS_BASE_PATH}/raw_data/2.Motorcycle/4.horn_of_motorcycle\"\n",
    "binary_df = spark.read.format(\"binaryFile\").load(hdfs_dir)\n",
    "\n",
    "# ğŸ”¹ UDF (User Defined Function) ì •ì˜: WAV â†’ MFCC ë³€í™˜\n",
    "def extract_mfcc(binary_data):\n",
    "    try:\n",
    "        audio_bytes = io.BytesIO(binary_data)  # ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ íŒŒì¼ë¡œ ë³€í™˜\n",
    "        sr, audio = wavfile.read(audio_bytes)  # scipyë¡œ ìƒ˜í”Œë§ ë ˆì´íŠ¸ í™•ì¸\n",
    "        audio_librosa, sr_librosa = librosa.load(audio_bytes, sr=None)  # librosaë¡œ ë¦¬ìƒ˜í”Œë§\n",
    "        mfcc = librosa.feature.mfcc(y=audio_librosa, sr=sr_librosa, n_mfcc=50)  # MFCC ì¶”ì¶œ\n",
    "        mfcc_mean = np.mean(mfcc, axis=1).astype(float)  # í‰ê·  ê³„ì‚°\n",
    "        return mfcc_mean.tolist()  # ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n",
    "    except Exception as e:\n",
    "        return None  # ì—ëŸ¬ ë°œìƒ ì‹œ None ë°˜í™˜\n",
    "\n",
    "# UDF ë“±ë¡\n",
    "mfcc_udf = udf(extract_mfcc, ArrayType(FloatType()))\n",
    "\n",
    "# ğŸ”¹ íŒŒì¼ ì´ë¦„ ì¶”ì¶œ UDF ì •ì˜\n",
    "def extract_filename(path):\n",
    "    return os.path.basename(path)\n",
    "\n",
    "filename_udf = udf(extract_filename, StringType())\n",
    "\n",
    "# ğŸ”¹ ë³€í™˜ ì ìš©\n",
    "df_mfcc = binary_df \\\n",
    "    .withColumn(\"fileName\", filename_udf(binary_df[\"path\"])) \\\n",
    "    .withColumn(\"mfcc_features\", mfcc_udf(binary_df[\"content\"]))\n",
    "\n",
    "# ğŸ”¹ ë°°ì—´ ë°ì´í„°ë¥¼ ê°œë³„ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜\n",
    "mfcc_columns = [f\"mfcc_{i+1}\" for i in range(50)]\n",
    "for i in range(50):\n",
    "    df_mfcc = df_mfcc.withColumn(mfcc_columns[i], df_mfcc[\"mfcc_features\"][i])\n",
    "\n",
    "# ğŸ”¹ ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì •ë¦¬\n",
    "df_mfcc = df_mfcc.select([\"fileName\"] + mfcc_columns)\n",
    "\n",
    "# ğŸ”¹ ê²°ê³¼ ì €ì¥ (HDFS)\n",
    "# output_path = \"hdfs://localhost:9000/shared_data/mfcc_features/\"\n",
    "# df_mfcc.write.csv(output_path, header=True, mode=\"overwrite\")\n",
    "\n",
    "# print(f\"âœ… MFCC ë°ì´í„°ê°€ HDFSì— ì €ì¥ë¨: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a498916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4560"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mfcc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d148c7e9-8493-4938-845b-b3933e367d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fileName: string (nullable = true)\n",
      " |-- mfcc_1: float (nullable = true)\n",
      " |-- mfcc_2: float (nullable = true)\n",
      " |-- mfcc_3: float (nullable = true)\n",
      " |-- mfcc_4: float (nullable = true)\n",
      " |-- mfcc_5: float (nullable = true)\n",
      " |-- mfcc_6: float (nullable = true)\n",
      " |-- mfcc_7: float (nullable = true)\n",
      " |-- mfcc_8: float (nullable = true)\n",
      " |-- mfcc_9: float (nullable = true)\n",
      " |-- mfcc_10: float (nullable = true)\n",
      " |-- mfcc_11: float (nullable = true)\n",
      " |-- mfcc_12: float (nullable = true)\n",
      " |-- mfcc_13: float (nullable = true)\n",
      " |-- mfcc_14: float (nullable = true)\n",
      " |-- mfcc_15: float (nullable = true)\n",
      " |-- mfcc_16: float (nullable = true)\n",
      " |-- mfcc_17: float (nullable = true)\n",
      " |-- mfcc_18: float (nullable = true)\n",
      " |-- mfcc_19: float (nullable = true)\n",
      " |-- mfcc_20: float (nullable = true)\n",
      " |-- mfcc_21: float (nullable = true)\n",
      " |-- mfcc_22: float (nullable = true)\n",
      " |-- mfcc_23: float (nullable = true)\n",
      " |-- mfcc_24: float (nullable = true)\n",
      " |-- mfcc_25: float (nullable = true)\n",
      " |-- mfcc_26: float (nullable = true)\n",
      " |-- mfcc_27: float (nullable = true)\n",
      " |-- mfcc_28: float (nullable = true)\n",
      " |-- mfcc_29: float (nullable = true)\n",
      " |-- mfcc_30: float (nullable = true)\n",
      " |-- mfcc_31: float (nullable = true)\n",
      " |-- mfcc_32: float (nullable = true)\n",
      " |-- mfcc_33: float (nullable = true)\n",
      " |-- mfcc_34: float (nullable = true)\n",
      " |-- mfcc_35: float (nullable = true)\n",
      " |-- mfcc_36: float (nullable = true)\n",
      " |-- mfcc_37: float (nullable = true)\n",
      " |-- mfcc_38: float (nullable = true)\n",
      " |-- mfcc_39: float (nullable = true)\n",
      " |-- mfcc_40: float (nullable = true)\n",
      " |-- mfcc_41: float (nullable = true)\n",
      " |-- mfcc_42: float (nullable = true)\n",
      " |-- mfcc_43: float (nullable = true)\n",
      " |-- mfcc_44: float (nullable = true)\n",
      " |-- mfcc_45: float (nullable = true)\n",
      " |-- mfcc_46: float (nullable = true)\n",
      " |-- mfcc_47: float (nullable = true)\n",
      " |-- mfcc_48: float (nullable = true)\n",
      " |-- mfcc_49: float (nullable = true)\n",
      " |-- mfcc_50: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_mfcc.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d9df333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„°ê°€ MySQLë¡œ ì„±ê³µì ìœ¼ë¡œ ì ì¬ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "df_mfcc.createOrReplaceTempView(\"wav_motor_horn50\")\n",
    "\n",
    "# SQL ì¿¼ë¦¬ ì‹¤í–‰í•˜ì—¬ ë°ì´í„° ì¶”ì¶œ\n",
    "df_mfcc = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM wav_motor_horn50\n",
    "\"\"\")\n",
    "\n",
    "# âœ… Config íŒŒì¼ì—ì„œ MySQL ì—°ê²° ì •ë³´ ë¡œë“œ\n",
    "mysql_url = f\"jdbc:mysql://{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}?useUnicode=true&characterEncoding=UTF-8\"\n",
    "mysql_properties = {\n",
    "    \"user\": DB_CONFIG[\"user\"],\n",
    "    \"password\": DB_CONFIG[\"password\"],\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "# MySQLë¡œ DataFrame ì ì¬ (ì¿¼ë¦¬ ê²°ê³¼ê°€ Noneì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)\n",
    "if df_mfcc is not None:\n",
    "    df_mfcc.write.jdbc(url=mysql_url, table=\"wav_motorcycle_horn_data50\", mode=\"overwrite\", properties=mysql_properties)\n",
    "    print(\"ë°ì´í„°ê°€ MySQLë¡œ ì„±ê³µì ìœ¼ë¡œ ì ì¬ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"ì¿¼ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ì¶”ì¶œì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7f84b3",
   "metadata": {},
   "source": [
    "## 2. wav_motor_driving_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d2392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import io\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
    "\n",
    "# HDFSì—ì„œ ëª¨ë“  WAV íŒŒì¼ ì½ê¸°\n",
    "hdfs_dir = f\"{config.HDFS_BASE_PATH}/raw_data/2.Motorcycle/5.driving_sound_of_motorcycle\"\n",
    "binary_df = spark.read.format(\"binaryFile\").load(hdfs_dir)\n",
    "\n",
    "# ğŸ”¹ UDF (User Defined Function) ì •ì˜: WAV â†’ MFCC ë³€í™˜\n",
    "def extract_mfcc(binary_data):\n",
    "    try:\n",
    "        audio_bytes = io.BytesIO(binary_data)  # ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ íŒŒì¼ë¡œ ë³€í™˜\n",
    "        sr, audio = wavfile.read(audio_bytes)  # scipyë¡œ ìƒ˜í”Œë§ ë ˆì´íŠ¸ í™•ì¸\n",
    "        audio_librosa, sr_librosa = librosa.load(audio_bytes, sr=None)  # librosaë¡œ ë¦¬ìƒ˜í”Œë§\n",
    "        mfcc = librosa.feature.mfcc(y=audio_librosa, sr=sr_librosa, n_mfcc=50)  # MFCC ì¶”ì¶œ\n",
    "        mfcc_mean = np.mean(mfcc, axis=1).astype(float)  # í‰ê·  ê³„ì‚°\n",
    "        return mfcc_mean.tolist()  # ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n",
    "    except Exception as e:\n",
    "        return None  # ì—ëŸ¬ ë°œìƒ ì‹œ None ë°˜í™˜\n",
    "\n",
    "# UDF ë“±ë¡\n",
    "mfcc_udf = udf(extract_mfcc, ArrayType(FloatType()))\n",
    "\n",
    "# ğŸ”¹ íŒŒì¼ ì´ë¦„ ì¶”ì¶œ UDF ì •ì˜\n",
    "def extract_filename(path):\n",
    "    return os.path.basename(path)\n",
    "\n",
    "filename_udf = udf(extract_filename, StringType())\n",
    "\n",
    "# ğŸ”¹ ë³€í™˜ ì ìš©\n",
    "df_mfcc = binary_df \\\n",
    "    .withColumn(\"fileName\", filename_udf(binary_df[\"path\"])) \\\n",
    "    .withColumn(\"mfcc_features\", mfcc_udf(binary_df[\"content\"]))\n",
    "\n",
    "# ğŸ”¹ ë°°ì—´ ë°ì´í„°ë¥¼ ê°œë³„ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜\n",
    "mfcc_columns = [f\"mfcc_{i+1}\" for i in range(50)]\n",
    "for i in range(50):\n",
    "    df_mfcc = df_mfcc.withColumn(mfcc_columns[i], df_mfcc[\"mfcc_features\"][i])\n",
    "\n",
    "# ğŸ”¹ ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì •ë¦¬\n",
    "df_mfcc = df_mfcc.select([\"fileName\"] + mfcc_columns)\n",
    "\n",
    "# ğŸ”¹ ê²°ê³¼ ì €ì¥ (HDFS)\n",
    "# output_path = \"hdfs://localhost:9000/shared_data/mfcc_features/\"\n",
    "# df_mfcc.write.csv(output_path, header=True, mode=\"overwrite\")\n",
    "\n",
    "# print(f\"âœ… MFCC ë°ì´í„°ê°€ HDFSì— ì €ì¥ë¨: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "517239d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4735"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mfcc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff39bfa-b534-4604-9e11-5c7acf2bd854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fileName: string (nullable = true)\n",
      " |-- mfcc_1: float (nullable = true)\n",
      " |-- mfcc_2: float (nullable = true)\n",
      " |-- mfcc_3: float (nullable = true)\n",
      " |-- mfcc_4: float (nullable = true)\n",
      " |-- mfcc_5: float (nullable = true)\n",
      " |-- mfcc_6: float (nullable = true)\n",
      " |-- mfcc_7: float (nullable = true)\n",
      " |-- mfcc_8: float (nullable = true)\n",
      " |-- mfcc_9: float (nullable = true)\n",
      " |-- mfcc_10: float (nullable = true)\n",
      " |-- mfcc_11: float (nullable = true)\n",
      " |-- mfcc_12: float (nullable = true)\n",
      " |-- mfcc_13: float (nullable = true)\n",
      " |-- mfcc_14: float (nullable = true)\n",
      " |-- mfcc_15: float (nullable = true)\n",
      " |-- mfcc_16: float (nullable = true)\n",
      " |-- mfcc_17: float (nullable = true)\n",
      " |-- mfcc_18: float (nullable = true)\n",
      " |-- mfcc_19: float (nullable = true)\n",
      " |-- mfcc_20: float (nullable = true)\n",
      " |-- mfcc_21: float (nullable = true)\n",
      " |-- mfcc_22: float (nullable = true)\n",
      " |-- mfcc_23: float (nullable = true)\n",
      " |-- mfcc_24: float (nullable = true)\n",
      " |-- mfcc_25: float (nullable = true)\n",
      " |-- mfcc_26: float (nullable = true)\n",
      " |-- mfcc_27: float (nullable = true)\n",
      " |-- mfcc_28: float (nullable = true)\n",
      " |-- mfcc_29: float (nullable = true)\n",
      " |-- mfcc_30: float (nullable = true)\n",
      " |-- mfcc_31: float (nullable = true)\n",
      " |-- mfcc_32: float (nullable = true)\n",
      " |-- mfcc_33: float (nullable = true)\n",
      " |-- mfcc_34: float (nullable = true)\n",
      " |-- mfcc_35: float (nullable = true)\n",
      " |-- mfcc_36: float (nullable = true)\n",
      " |-- mfcc_37: float (nullable = true)\n",
      " |-- mfcc_38: float (nullable = true)\n",
      " |-- mfcc_39: float (nullable = true)\n",
      " |-- mfcc_40: float (nullable = true)\n",
      " |-- mfcc_41: float (nullable = true)\n",
      " |-- mfcc_42: float (nullable = true)\n",
      " |-- mfcc_43: float (nullable = true)\n",
      " |-- mfcc_44: float (nullable = true)\n",
      " |-- mfcc_45: float (nullable = true)\n",
      " |-- mfcc_46: float (nullable = true)\n",
      " |-- mfcc_47: float (nullable = true)\n",
      " |-- mfcc_48: float (nullable = true)\n",
      " |-- mfcc_49: float (nullable = true)\n",
      " |-- mfcc_50: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_mfcc.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c2a8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„°ê°€ MySQLë¡œ ì„±ê³µì ìœ¼ë¡œ ì ì¬ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "df_mfcc.createOrReplaceTempView(\"wav_motor_driving50\")\n",
    "\n",
    "# SQL ì¿¼ë¦¬ ì‹¤í–‰í•˜ì—¬ ë°ì´í„° ì¶”ì¶œ\n",
    "df_mfcc = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM wav_motor_driving50\n",
    "\"\"\")\n",
    "\n",
    "# âœ… Config íŒŒì¼ì—ì„œ MySQL ì—°ê²° ì •ë³´ ë¡œë“œ\n",
    "mysql_url = f\"jdbc:mysql://{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}?useUnicode=true&characterEncoding=UTF-8\"\n",
    "mysql_properties = {\n",
    "    \"user\": DB_CONFIG[\"user\"],\n",
    "    \"password\": DB_CONFIG[\"password\"],\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "# MySQLë¡œ DataFrame ì ì¬ (ì¿¼ë¦¬ ê²°ê³¼ê°€ Noneì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)\n",
    "if df_mfcc is not None:\n",
    "    df_mfcc.write.jdbc(url=mysql_url, table=\"wav_motorcycle_driving_data50\", mode=\"overwrite\", properties=mysql_properties)\n",
    "    print(\"ë°ì´í„°ê°€ MySQLë¡œ ì„±ê³µì ìœ¼ë¡œ ì ì¬ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"ì¿¼ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ì¶”ì¶œì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70aec751",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ba9954-a8c3-4624-855a-4749bb3e6d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(ml_env_python3.6)",
   "language": "python",
   "name": "ml_env_python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
