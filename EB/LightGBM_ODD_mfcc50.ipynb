{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c619aa16-8717-46d3-be1d-44aa38bf72a1",
   "metadata": {},
   "source": [
    "# ë°ì´í„° í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344916b7-21de-4e02-92f3-4203de25ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import config \n",
    "from config import DB_CONFIG\n",
    "import pymysql  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad936e2-f844-4fdc-99ae-9876b0157418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySQL ì—°ê²°\n",
    "conn = pymysql.connect(\n",
    "    host=DB_CONFIG['host'],\n",
    "    user=DB_CONFIG['user'],\n",
    "    password=DB_CONFIG['password'],\n",
    "    database=DB_CONFIG['database'],\n",
    "    port=DB_CONFIG['port']\n",
    ")\n",
    "\n",
    "car_siren = f\"SELECT * FROM merge50_car_siren\"\n",
    "car_horn = f\"SELECT * FROM merge50_car_horn\"\n",
    "car_driving = f'SELECT * FROM merge50_car_driving'\n",
    "motorcycle_horn  = f'SELECT * FROM merge50_motorcycle_horn'\n",
    "motorcycle_driving  = f'SELECT * FROM merge50_motorcycle_driving'\n",
    "\n",
    "car_siren_df =  pd.read_sql(car_siren, conn)\n",
    "car_horn_df = pd.read_sql(car_horn, conn) \n",
    "car_driving_df = pd.read_sql(car_driving, conn) \n",
    "motorcycle_horn_df= pd.read_sql(motorcycle_horn, conn) \n",
    "motorcycle_driving_df = pd.read_sql(motorcycle_driving, conn) \n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8735bd5-74f9-439d-9f27-ede4732854c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_siren ë°ì´í„° ê°œìˆ˜: 1990\n",
      "car_horn ë°ì´í„° ê°œìˆ˜: 3189\n",
      "car_driving ë°ì´í„° ê°œìˆ˜: 1682\n",
      "motorcycle_horn ë°ì´í„° ê°œìˆ˜: 4560\n",
      "motorcycle_driving ë°ì´í„° ê°œìˆ˜: 4735\n"
     ]
    }
   ],
   "source": [
    "print(f'car_siren ë°ì´í„° ê°œìˆ˜: {car_siren_df.shape[0]}')\n",
    "print(f'car_horn ë°ì´í„° ê°œìˆ˜: {car_horn_df.shape[0]}')\n",
    "print(f'car_driving ë°ì´í„° ê°œìˆ˜: {car_driving_df.shape[0]}')\n",
    "print(f'motorcycle_horn ë°ì´í„° ê°œìˆ˜: {motorcycle_horn_df.shape[0]}')\n",
    "print(f'motorcycle_driving ë°ì´í„° ê°œìˆ˜: {motorcycle_driving_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf70ad4-b037-44fc-ac4b-7ea51324fe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1990 entries, 0 to 1989\n",
      "Data columns (total 82 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   fileName       1990 non-null   object \n",
      " 1   labelName      1990 non-null   object \n",
      " 2   area_start     1990 non-null   float64\n",
      " 3   area_end       1990 non-null   float64\n",
      " 4   category_01    1990 non-null   object \n",
      " 5   category_02    1990 non-null   object \n",
      " 6   category_03    1990 non-null   object \n",
      " 7   decibel        1990 non-null   int64  \n",
      " 8   soundQuality   1990 non-null   object \n",
      " 9   subCategory    1990 non-null   object \n",
      " 10  bitRate        1990 non-null   object \n",
      " 11  duration       1990 non-null   float64\n",
      " 12  fileFormat     1990 non-null   object \n",
      " 13  fileSize       1990 non-null   int64  \n",
      " 14  recodingType   1990 non-null   object \n",
      " 15  sampleRate     1990 non-null   object \n",
      " 16  acqDevice      1990 non-null   object \n",
      " 17  acqMethod      1990 non-null   object \n",
      " 18  acqType        1990 non-null   object \n",
      " 19  areaUse        1990 non-null   object \n",
      " 20  dayNight       1990 non-null   object \n",
      " 21  direction      1990 non-null   object \n",
      " 22  distance       1990 non-null   object \n",
      " 23  district       1990 non-null   object \n",
      " 24  latitude       1990 non-null   float64\n",
      " 25  longitude      1990 non-null   float64\n",
      " 26  micClass       1990 non-null   object \n",
      " 27  obstacle       1990 non-null   object \n",
      " 28  place          1990 non-null   object \n",
      " 29  recordingTime  1990 non-null   object \n",
      " 30  urban          1990 non-null   object \n",
      " 31  weather        1990 non-null   object \n",
      " 32  mfcc_1         1990 non-null   float64\n",
      " 33  mfcc_2         1990 non-null   float64\n",
      " 34  mfcc_3         1990 non-null   float64\n",
      " 35  mfcc_4         1990 non-null   float64\n",
      " 36  mfcc_5         1990 non-null   float64\n",
      " 37  mfcc_6         1990 non-null   float64\n",
      " 38  mfcc_7         1990 non-null   float64\n",
      " 39  mfcc_8         1990 non-null   float64\n",
      " 40  mfcc_9         1990 non-null   float64\n",
      " 41  mfcc_10        1990 non-null   float64\n",
      " 42  mfcc_11        1990 non-null   float64\n",
      " 43  mfcc_12        1990 non-null   float64\n",
      " 44  mfcc_13        1990 non-null   float64\n",
      " 45  mfcc_14        1990 non-null   float64\n",
      " 46  mfcc_15        1990 non-null   float64\n",
      " 47  mfcc_16        1990 non-null   float64\n",
      " 48  mfcc_17        1990 non-null   float64\n",
      " 49  mfcc_18        1990 non-null   float64\n",
      " 50  mfcc_19        1990 non-null   float64\n",
      " 51  mfcc_20        1990 non-null   float64\n",
      " 52  mfcc_21        1990 non-null   float64\n",
      " 53  mfcc_22        1990 non-null   float64\n",
      " 54  mfcc_23        1990 non-null   float64\n",
      " 55  mfcc_24        1990 non-null   float64\n",
      " 56  mfcc_25        1990 non-null   float64\n",
      " 57  mfcc_26        1990 non-null   float64\n",
      " 58  mfcc_27        1990 non-null   float64\n",
      " 59  mfcc_28        1990 non-null   float64\n",
      " 60  mfcc_29        1990 non-null   float64\n",
      " 61  mfcc_30        1990 non-null   float64\n",
      " 62  mfcc_31        1990 non-null   float64\n",
      " 63  mfcc_32        1990 non-null   float64\n",
      " 64  mfcc_33        1990 non-null   float64\n",
      " 65  mfcc_34        1990 non-null   float64\n",
      " 66  mfcc_35        1990 non-null   float64\n",
      " 67  mfcc_36        1990 non-null   float64\n",
      " 68  mfcc_37        1990 non-null   float64\n",
      " 69  mfcc_38        1990 non-null   float64\n",
      " 70  mfcc_39        1990 non-null   float64\n",
      " 71  mfcc_40        1990 non-null   float64\n",
      " 72  mfcc_41        1990 non-null   float64\n",
      " 73  mfcc_42        1990 non-null   float64\n",
      " 74  mfcc_43        1990 non-null   float64\n",
      " 75  mfcc_44        1990 non-null   float64\n",
      " 76  mfcc_45        1990 non-null   float64\n",
      " 77  mfcc_46        1990 non-null   float64\n",
      " 78  mfcc_47        1990 non-null   float64\n",
      " 79  mfcc_48        1990 non-null   float64\n",
      " 80  mfcc_49        1990 non-null   float64\n",
      " 81  mfcc_50        1990 non-null   float64\n",
      "dtypes: float64(55), int64(2), object(25)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "car_siren_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7712a8ba-db33-4b7d-a24c-d827fc063681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_41</th>\n",
       "      <th>mfcc_42</th>\n",
       "      <th>mfcc_43</th>\n",
       "      <th>mfcc_44</th>\n",
       "      <th>mfcc_45</th>\n",
       "      <th>mfcc_46</th>\n",
       "      <th>mfcc_47</th>\n",
       "      <th>mfcc_48</th>\n",
       "      <th>mfcc_49</th>\n",
       "      <th>mfcc_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-391.00430</td>\n",
       "      <td>107.641975</td>\n",
       "      <td>64.204640</td>\n",
       "      <td>33.718952</td>\n",
       "      <td>20.630340</td>\n",
       "      <td>13.337987</td>\n",
       "      <td>9.100019</td>\n",
       "      <td>8.873220</td>\n",
       "      <td>9.340549</td>\n",
       "      <td>8.287990</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.194056</td>\n",
       "      <td>-0.757743</td>\n",
       "      <td>-2.858810</td>\n",
       "      <td>-5.101422</td>\n",
       "      <td>-0.198150</td>\n",
       "      <td>7.001447</td>\n",
       "      <td>6.203896</td>\n",
       "      <td>-2.862313</td>\n",
       "      <td>-10.336964</td>\n",
       "      <td>-8.593492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-233.66284</td>\n",
       "      <td>87.917620</td>\n",
       "      <td>45.434906</td>\n",
       "      <td>19.435001</td>\n",
       "      <td>9.098841</td>\n",
       "      <td>32.400368</td>\n",
       "      <td>5.817845</td>\n",
       "      <td>9.204194</td>\n",
       "      <td>14.611247</td>\n",
       "      <td>20.294502</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.923782</td>\n",
       "      <td>8.347244</td>\n",
       "      <td>-2.440833</td>\n",
       "      <td>-17.408949</td>\n",
       "      <td>-5.891588</td>\n",
       "      <td>22.778133</td>\n",
       "      <td>21.374588</td>\n",
       "      <td>-19.310514</td>\n",
       "      <td>-26.457247</td>\n",
       "      <td>4.794274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-318.16153</td>\n",
       "      <td>126.123180</td>\n",
       "      <td>43.729805</td>\n",
       "      <td>-11.429483</td>\n",
       "      <td>-5.223235</td>\n",
       "      <td>13.667998</td>\n",
       "      <td>0.934844</td>\n",
       "      <td>10.497743</td>\n",
       "      <td>2.401143</td>\n",
       "      <td>22.281258</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.953082</td>\n",
       "      <td>1.538178</td>\n",
       "      <td>-0.032047</td>\n",
       "      <td>-10.759938</td>\n",
       "      <td>-10.296665</td>\n",
       "      <td>14.938017</td>\n",
       "      <td>19.099138</td>\n",
       "      <td>-5.256958</td>\n",
       "      <td>-27.792421</td>\n",
       "      <td>-7.377015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-385.20926</td>\n",
       "      <td>140.265410</td>\n",
       "      <td>57.263832</td>\n",
       "      <td>-7.932145</td>\n",
       "      <td>-3.877982</td>\n",
       "      <td>14.155136</td>\n",
       "      <td>6.298158</td>\n",
       "      <td>11.397833</td>\n",
       "      <td>2.566783</td>\n",
       "      <td>15.076704</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.018665</td>\n",
       "      <td>2.996135</td>\n",
       "      <td>-0.142866</td>\n",
       "      <td>-8.995171</td>\n",
       "      <td>-4.227169</td>\n",
       "      <td>8.116351</td>\n",
       "      <td>11.163322</td>\n",
       "      <td>-4.992955</td>\n",
       "      <td>-16.359087</td>\n",
       "      <td>-5.441961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-382.12450</td>\n",
       "      <td>150.004900</td>\n",
       "      <td>61.439040</td>\n",
       "      <td>-17.890905</td>\n",
       "      <td>-7.740589</td>\n",
       "      <td>15.947204</td>\n",
       "      <td>3.806582</td>\n",
       "      <td>7.909450</td>\n",
       "      <td>2.633213</td>\n",
       "      <td>14.426663</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.330876</td>\n",
       "      <td>2.107300</td>\n",
       "      <td>1.768516</td>\n",
       "      <td>-10.489394</td>\n",
       "      <td>-4.815802</td>\n",
       "      <td>9.592706</td>\n",
       "      <td>12.866017</td>\n",
       "      <td>-3.469832</td>\n",
       "      <td>-20.286922</td>\n",
       "      <td>-6.563427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>-99.19382</td>\n",
       "      <td>119.270660</td>\n",
       "      <td>-76.342830</td>\n",
       "      <td>14.679804</td>\n",
       "      <td>-26.403290</td>\n",
       "      <td>5.220899</td>\n",
       "      <td>-15.944427</td>\n",
       "      <td>-0.425459</td>\n",
       "      <td>-14.378425</td>\n",
       "      <td>-2.452169</td>\n",
       "      <td>...</td>\n",
       "      <td>1.322109</td>\n",
       "      <td>-1.603073</td>\n",
       "      <td>-0.969422</td>\n",
       "      <td>-0.030491</td>\n",
       "      <td>-3.283236</td>\n",
       "      <td>-4.058084</td>\n",
       "      <td>-2.597992</td>\n",
       "      <td>-0.028827</td>\n",
       "      <td>1.399276</td>\n",
       "      <td>-4.661576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>-292.45557</td>\n",
       "      <td>203.069000</td>\n",
       "      <td>-53.426810</td>\n",
       "      <td>37.105576</td>\n",
       "      <td>6.516268</td>\n",
       "      <td>10.316400</td>\n",
       "      <td>11.667080</td>\n",
       "      <td>1.168588</td>\n",
       "      <td>17.977980</td>\n",
       "      <td>5.434537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412159</td>\n",
       "      <td>-0.795219</td>\n",
       "      <td>-1.426503</td>\n",
       "      <td>-3.167590</td>\n",
       "      <td>-2.035457</td>\n",
       "      <td>0.571453</td>\n",
       "      <td>4.668703</td>\n",
       "      <td>3.238892</td>\n",
       "      <td>-5.142219</td>\n",
       "      <td>-4.995093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>-198.79451</td>\n",
       "      <td>201.686460</td>\n",
       "      <td>-87.792480</td>\n",
       "      <td>-11.408583</td>\n",
       "      <td>-14.657739</td>\n",
       "      <td>-5.088332</td>\n",
       "      <td>-0.388612</td>\n",
       "      <td>-13.570362</td>\n",
       "      <td>6.362044</td>\n",
       "      <td>-11.089597</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.205375</td>\n",
       "      <td>0.633744</td>\n",
       "      <td>2.143693</td>\n",
       "      <td>-4.530044</td>\n",
       "      <td>-7.654323</td>\n",
       "      <td>3.844430</td>\n",
       "      <td>9.282047</td>\n",
       "      <td>2.180258</td>\n",
       "      <td>-6.707889</td>\n",
       "      <td>-3.188458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>-247.43971</td>\n",
       "      <td>186.716000</td>\n",
       "      <td>-45.675808</td>\n",
       "      <td>47.491760</td>\n",
       "      <td>18.612213</td>\n",
       "      <td>16.028240</td>\n",
       "      <td>8.016017</td>\n",
       "      <td>3.121070</td>\n",
       "      <td>13.013415</td>\n",
       "      <td>4.386095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659112</td>\n",
       "      <td>-2.346271</td>\n",
       "      <td>-1.647404</td>\n",
       "      <td>-0.503469</td>\n",
       "      <td>0.055166</td>\n",
       "      <td>-0.353136</td>\n",
       "      <td>-0.114590</td>\n",
       "      <td>1.304396</td>\n",
       "      <td>0.613524</td>\n",
       "      <td>-0.592904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>-295.30887</td>\n",
       "      <td>224.132390</td>\n",
       "      <td>-42.393883</td>\n",
       "      <td>30.421978</td>\n",
       "      <td>18.980920</td>\n",
       "      <td>9.521865</td>\n",
       "      <td>16.274446</td>\n",
       "      <td>0.520351</td>\n",
       "      <td>13.609183</td>\n",
       "      <td>2.586846</td>\n",
       "      <td>...</td>\n",
       "      <td>4.073492</td>\n",
       "      <td>-0.281517</td>\n",
       "      <td>1.813115</td>\n",
       "      <td>1.477441</td>\n",
       "      <td>-1.411676</td>\n",
       "      <td>-2.991270</td>\n",
       "      <td>-2.364653</td>\n",
       "      <td>2.412057</td>\n",
       "      <td>2.298984</td>\n",
       "      <td>-1.866335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3189 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mfcc_1      mfcc_2     mfcc_3     mfcc_4     mfcc_5     mfcc_6  \\\n",
       "0    -391.00430  107.641975  64.204640  33.718952  20.630340  13.337987   \n",
       "1    -233.66284   87.917620  45.434906  19.435001   9.098841  32.400368   \n",
       "2    -318.16153  126.123180  43.729805 -11.429483  -5.223235  13.667998   \n",
       "3    -385.20926  140.265410  57.263832  -7.932145  -3.877982  14.155136   \n",
       "4    -382.12450  150.004900  61.439040 -17.890905  -7.740589  15.947204   \n",
       "...         ...         ...        ...        ...        ...        ...   \n",
       "3184  -99.19382  119.270660 -76.342830  14.679804 -26.403290   5.220899   \n",
       "3185 -292.45557  203.069000 -53.426810  37.105576   6.516268  10.316400   \n",
       "3186 -198.79451  201.686460 -87.792480 -11.408583 -14.657739  -5.088332   \n",
       "3187 -247.43971  186.716000 -45.675808  47.491760  18.612213  16.028240   \n",
       "3188 -295.30887  224.132390 -42.393883  30.421978  18.980920   9.521865   \n",
       "\n",
       "         mfcc_7     mfcc_8     mfcc_9    mfcc_10  ...   mfcc_41   mfcc_42  \\\n",
       "0      9.100019   8.873220   9.340549   8.287990  ... -1.194056 -0.757743   \n",
       "1      5.817845   9.204194  14.611247  20.294502  ... -7.923782  8.347244   \n",
       "2      0.934844  10.497743   2.401143  22.281258  ... -5.953082  1.538178   \n",
       "3      6.298158  11.397833   2.566783  15.076704  ... -5.018665  2.996135   \n",
       "4      3.806582   7.909450   2.633213  14.426663  ... -5.330876  2.107300   \n",
       "...         ...        ...        ...        ...  ...       ...       ...   \n",
       "3184 -15.944427  -0.425459 -14.378425  -2.452169  ...  1.322109 -1.603073   \n",
       "3185  11.667080   1.168588  17.977980   5.434537  ...  0.412159 -0.795219   \n",
       "3186  -0.388612 -13.570362   6.362044 -11.089597  ... -1.205375  0.633744   \n",
       "3187   8.016017   3.121070  13.013415   4.386095  ...  0.659112 -2.346271   \n",
       "3188  16.274446   0.520351  13.609183   2.586846  ...  4.073492 -0.281517   \n",
       "\n",
       "       mfcc_43    mfcc_44    mfcc_45    mfcc_46    mfcc_47    mfcc_48  \\\n",
       "0    -2.858810  -5.101422  -0.198150   7.001447   6.203896  -2.862313   \n",
       "1    -2.440833 -17.408949  -5.891588  22.778133  21.374588 -19.310514   \n",
       "2    -0.032047 -10.759938 -10.296665  14.938017  19.099138  -5.256958   \n",
       "3    -0.142866  -8.995171  -4.227169   8.116351  11.163322  -4.992955   \n",
       "4     1.768516 -10.489394  -4.815802   9.592706  12.866017  -3.469832   \n",
       "...        ...        ...        ...        ...        ...        ...   \n",
       "3184 -0.969422  -0.030491  -3.283236  -4.058084  -2.597992  -0.028827   \n",
       "3185 -1.426503  -3.167590  -2.035457   0.571453   4.668703   3.238892   \n",
       "3186  2.143693  -4.530044  -7.654323   3.844430   9.282047   2.180258   \n",
       "3187 -1.647404  -0.503469   0.055166  -0.353136  -0.114590   1.304396   \n",
       "3188  1.813115   1.477441  -1.411676  -2.991270  -2.364653   2.412057   \n",
       "\n",
       "        mfcc_49   mfcc_50  \n",
       "0    -10.336964 -8.593492  \n",
       "1    -26.457247  4.794274  \n",
       "2    -27.792421 -7.377015  \n",
       "3    -16.359087 -5.441961  \n",
       "4    -20.286922 -6.563427  \n",
       "...         ...       ...  \n",
       "3184   1.399276 -4.661576  \n",
       "3185  -5.142219 -4.995093  \n",
       "3186  -6.707889 -3.188458  \n",
       "3187   0.613524 -0.592904  \n",
       "3188   2.298984 -1.866335  \n",
       "\n",
       "[3189 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_horn_df.iloc[ : ,-50:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96996849-7c10-47fb-b4c8-947e65402661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_combined í–‰ ê°œìˆ˜: 16156\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileName</th>\n",
       "      <th>labelName</th>\n",
       "      <th>area_start</th>\n",
       "      <th>area_end</th>\n",
       "      <th>category_01</th>\n",
       "      <th>category_02</th>\n",
       "      <th>category_03</th>\n",
       "      <th>decibel</th>\n",
       "      <th>soundQuality</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_41</th>\n",
       "      <th>mfcc_42</th>\n",
       "      <th>mfcc_43</th>\n",
       "      <th>mfcc_44</th>\n",
       "      <th>mfcc_45</th>\n",
       "      <th>mfcc_46</th>\n",
       "      <th>mfcc_47</th>\n",
       "      <th>mfcc_48</th>\n",
       "      <th>mfcc_49</th>\n",
       "      <th>mfcc_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.car_horn_87900_1.wav</td>\n",
       "      <td>1.car_horn_87900_1.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.719</td>\n",
       "      <td>êµí†µì†ŒìŒ</td>\n",
       "      <td>ìë™ì°¨</td>\n",
       "      <td>ì°¨ëŸ‰ê²½ì </td>\n",
       "      <td>116</td>\n",
       "      <td>ì •ìƒ</td>\n",
       "      <td>ì†Œí˜•ì°¨ê²½ì </td>\n",
       "      <td>...</td>\n",
       "      <td>-1.194056</td>\n",
       "      <td>-0.757743</td>\n",
       "      <td>-2.858810</td>\n",
       "      <td>-5.101422</td>\n",
       "      <td>-0.198150</td>\n",
       "      <td>7.001447</td>\n",
       "      <td>6.203896</td>\n",
       "      <td>-2.862313</td>\n",
       "      <td>-10.336964</td>\n",
       "      <td>-8.593492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.car_horn_87964_1.wav</td>\n",
       "      <td>1.car_horn_87964_1.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.747</td>\n",
       "      <td>êµí†µì†ŒìŒ</td>\n",
       "      <td>ìë™ì°¨</td>\n",
       "      <td>ì°¨ëŸ‰ê²½ì </td>\n",
       "      <td>102</td>\n",
       "      <td>ì •ìƒ</td>\n",
       "      <td>ì†Œí˜•ì°¨ê²½ì </td>\n",
       "      <td>...</td>\n",
       "      <td>-7.923782</td>\n",
       "      <td>8.347244</td>\n",
       "      <td>-2.440833</td>\n",
       "      <td>-17.408949</td>\n",
       "      <td>-5.891588</td>\n",
       "      <td>22.778133</td>\n",
       "      <td>21.374588</td>\n",
       "      <td>-19.310514</td>\n",
       "      <td>-26.457247</td>\n",
       "      <td>4.794274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.car_horn_87987_1.wav</td>\n",
       "      <td>1.car_horn_87987_1.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.217</td>\n",
       "      <td>êµí†µì†ŒìŒ</td>\n",
       "      <td>ìë™ì°¨</td>\n",
       "      <td>ì°¨ëŸ‰ê²½ì </td>\n",
       "      <td>112</td>\n",
       "      <td>ì •ìƒ</td>\n",
       "      <td>ì†Œí˜•ì°¨ê²½ì </td>\n",
       "      <td>...</td>\n",
       "      <td>-5.953082</td>\n",
       "      <td>1.538178</td>\n",
       "      <td>-0.032047</td>\n",
       "      <td>-10.759938</td>\n",
       "      <td>-10.296665</td>\n",
       "      <td>14.938017</td>\n",
       "      <td>19.099138</td>\n",
       "      <td>-5.256958</td>\n",
       "      <td>-27.792421</td>\n",
       "      <td>-7.377015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.car_horn_88000_1.wav</td>\n",
       "      <td>1.car_horn_88000_1.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.389</td>\n",
       "      <td>êµí†µì†ŒìŒ</td>\n",
       "      <td>ìë™ì°¨</td>\n",
       "      <td>ì°¨ëŸ‰ê²½ì </td>\n",
       "      <td>112</td>\n",
       "      <td>ì •ìƒ</td>\n",
       "      <td>ì†Œí˜•ì°¨ê²½ì </td>\n",
       "      <td>...</td>\n",
       "      <td>-5.018665</td>\n",
       "      <td>2.996135</td>\n",
       "      <td>-0.142866</td>\n",
       "      <td>-8.995171</td>\n",
       "      <td>-4.227169</td>\n",
       "      <td>8.116351</td>\n",
       "      <td>11.163322</td>\n",
       "      <td>-4.992955</td>\n",
       "      <td>-16.359087</td>\n",
       "      <td>-5.441961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.car_horn_88001_1.wav</td>\n",
       "      <td>1.car_horn_88001_1.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.207</td>\n",
       "      <td>êµí†µì†ŒìŒ</td>\n",
       "      <td>ìë™ì°¨</td>\n",
       "      <td>ì°¨ëŸ‰ê²½ì </td>\n",
       "      <td>122</td>\n",
       "      <td>ì •ìƒ</td>\n",
       "      <td>ì†Œí˜•ì°¨ê²½ì </td>\n",
       "      <td>...</td>\n",
       "      <td>-5.330876</td>\n",
       "      <td>2.107300</td>\n",
       "      <td>1.768516</td>\n",
       "      <td>-10.489394</td>\n",
       "      <td>-4.815802</td>\n",
       "      <td>9.592706</td>\n",
       "      <td>12.866017</td>\n",
       "      <td>-3.469832</td>\n",
       "      <td>-20.286922</td>\n",
       "      <td>-6.563427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fileName               labelName  area_start  area_end  \\\n",
       "0  1.car_horn_87900_1.wav  1.car_horn_87900_1.wav         2.0    58.719   \n",
       "1  1.car_horn_87964_1.wav  1.car_horn_87964_1.wav         2.0    59.747   \n",
       "2  1.car_horn_87987_1.wav  1.car_horn_87987_1.wav         2.0    59.217   \n",
       "3  1.car_horn_88000_1.wav  1.car_horn_88000_1.wav         2.0    57.389   \n",
       "4  1.car_horn_88001_1.wav  1.car_horn_88001_1.wav         2.0    58.207   \n",
       "\n",
       "  category_01 category_02 category_03  decibel soundQuality subCategory  ...  \\\n",
       "0        êµí†µì†ŒìŒ         ìë™ì°¨        ì°¨ëŸ‰ê²½ì       116           ì •ìƒ       ì†Œí˜•ì°¨ê²½ì   ...   \n",
       "1        êµí†µì†ŒìŒ         ìë™ì°¨        ì°¨ëŸ‰ê²½ì       102           ì •ìƒ       ì†Œí˜•ì°¨ê²½ì   ...   \n",
       "2        êµí†µì†ŒìŒ         ìë™ì°¨        ì°¨ëŸ‰ê²½ì       112           ì •ìƒ       ì†Œí˜•ì°¨ê²½ì   ...   \n",
       "3        êµí†µì†ŒìŒ         ìë™ì°¨        ì°¨ëŸ‰ê²½ì       112           ì •ìƒ       ì†Œí˜•ì°¨ê²½ì   ...   \n",
       "4        êµí†µì†ŒìŒ         ìë™ì°¨        ì°¨ëŸ‰ê²½ì       122           ì •ìƒ       ì†Œí˜•ì°¨ê²½ì   ...   \n",
       "\n",
       "    mfcc_41   mfcc_42   mfcc_43    mfcc_44    mfcc_45    mfcc_46    mfcc_47  \\\n",
       "0 -1.194056 -0.757743 -2.858810  -5.101422  -0.198150   7.001447   6.203896   \n",
       "1 -7.923782  8.347244 -2.440833 -17.408949  -5.891588  22.778133  21.374588   \n",
       "2 -5.953082  1.538178 -0.032047 -10.759938 -10.296665  14.938017  19.099138   \n",
       "3 -5.018665  2.996135 -0.142866  -8.995171  -4.227169   8.116351  11.163322   \n",
       "4 -5.330876  2.107300  1.768516 -10.489394  -4.815802   9.592706  12.866017   \n",
       "\n",
       "     mfcc_48    mfcc_49   mfcc_50  \n",
       "0  -2.862313 -10.336964 -8.593492  \n",
       "1 -19.310514 -26.457247  4.794274  \n",
       "2  -5.256958 -27.792421 -7.377015  \n",
       "3  -4.992955 -16.359087 -5.441961  \n",
       "4  -3.469832 -20.286922 -6.563427  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ë°ì´í„°í”„ë ˆì„ ë³‘í•© \n",
    "df_combined = pd.concat([car_horn_df, car_siren_df,car_driving_df,motorcycle_horn_df,motorcycle_driving_df], ignore_index=True)\n",
    "\n",
    "print(f'df_combined í–‰ ê°œìˆ˜: {len(df_combined)}') \n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d930cb64-1813-49aa-8522-f91662570811",
   "metadata": {},
   "source": [
    "# lightGBM + ODD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "860f8fa4-0944-4f3c-a5b5-11b9c71fb060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "LightGBM ì •í™•ë„: 0.9449\n",
      "\n",
      "Confusion Matrix:\n",
      "        ì´ë¥œì°¨ê²½ì   ì´ë¥œì°¨ì£¼í–‰ìŒ  ì°¨ëŸ‰ê²½ì   ì°¨ëŸ‰ì‚¬ì´ë Œ  ì°¨ëŸ‰ì£¼í–‰ìŒ\n",
      "ì´ë¥œì°¨ê²½ì      902       2    44      1      0\n",
      "ì´ë¥œì°¨ì£¼í–‰ìŒ      0     885     3      1     26\n",
      "ì°¨ëŸ‰ê²½ì        24      10   582      1      4\n",
      "ì°¨ëŸ‰ì‚¬ì´ë Œ       0      11     3    401      7\n",
      "ì°¨ëŸ‰ì£¼í–‰ìŒ       0      40     0      1    284\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ì´ë¥œì°¨ê²½ì        0.97      0.95      0.96       949\n",
      "      ì´ë¥œì°¨ì£¼í–‰ìŒ       0.93      0.97      0.95       915\n",
      "        ì°¨ëŸ‰ê²½ì        0.92      0.94      0.93       621\n",
      "       ì°¨ëŸ‰ì‚¬ì´ë Œ       0.99      0.95      0.97       422\n",
      "       ì°¨ëŸ‰ì£¼í–‰ìŒ       0.88      0.87      0.88       325\n",
      "\n",
      "    accuracy                           0.94      3232\n",
      "   macro avg       0.94      0.94      0.94      3232\n",
      "weighted avg       0.95      0.94      0.95      3232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# ë ˆì´ë¸”(label)ê³¼ í”¼ì²˜(features) ë¶„ë¦¬\n",
    "X = df_combined.iloc[:, -50:]  # ë§ˆì§€ë§‰ 13ê°œ ì»¬ëŸ¼ì„ íŠ¹ì„±(MFCC)ìœ¼ë¡œ ì‚¬ìš©\n",
    "y = df_combined['category_03'].astype('category').cat.codes  # ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ë³€í™˜\n",
    "\n",
    "# ë²”ì£¼í˜• ë°ì´í„°(ë ˆì´ë¸”) ìˆ«ìë¡œ ë³€í™˜\n",
    "y = y.astype('category').cat.codes\n",
    "\n",
    "# í´ë˜ìŠ¤ ë ˆì´ë¸” ë§¤í•‘\n",
    "class_labels = df_combined['category_03'].astype('category').cat.categories\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë¶„í•  (train: 80%, test: 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "num_classes = len(set(y))\n",
    "print(num_classes)\n",
    "\n",
    "# LightGBM ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "model = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=-1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# í‰ê°€ ê²°ê³¼ ì¶œë ¥\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"LightGBM ì •í™•ë„: {acc:.4f}\")\n",
    "\n",
    "# í˜¼ë™ í–‰ë ¬ ë° ë¶„ë¥˜ ë³´ê³ ì„œ ì¶œë ¥\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred), index=class_labels, columns=class_labels)\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_labels.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab4ae78b-3519-420b-84be-85168b925e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "model = lgb.LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ëª¨ë¸ ì €ì¥ (Booster ê°ì²´ ì‚¬ìš©)\n",
    "model.booster_.save_model('lgbm_model.txt')\n",
    "\n",
    "print(\"ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a0f392-c2f4-4451-9450-40fe226025b4",
   "metadata": {},
   "source": [
    "# df_etc ê¸°íƒ€ ì†ŒìŒ (ì—´ì°¨, ë¹„í–‰ê¸°) í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f06e5e2-5d44-44c2-b2eb-aef3d3dd78eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = \"/home/ubuntu/data/etc_noise_data_test\"\n",
    "\n",
    "# ê¸°ì¡´ ë°ì´í„°í”„ë ˆì„ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "try:\n",
    "    df_combined\n",
    "except NameError:\n",
    "    df_combined = pd.DataFrame()  # ì—†ìœ¼ë©´ ë¹ˆ ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "\n",
    "json_data = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".json\"):\n",
    "        with open(os.path.join(data_dir, file), \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "            annotations = data.get(\"annotations\", [])\n",
    "            annotation = annotations[0] if annotations and isinstance(annotations, list) else {}\n",
    "\n",
    "            # JSON íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°\n",
    "            base_name = os.path.splitext(file)[0]\n",
    "\n",
    "            json_data.append({\n",
    "                \"baseName\": base_name,  # í™•ì¥ì ì—†ëŠ” íŒŒì¼ëª… ì €ì¥\n",
    "                \"fileName\": data[\"audio\"][\"fileName\"],\n",
    "                \"labelName\": annotation.get(\"labelName\", None),\n",
    "                \"area_start\": annotation.get(\"area\", {}).get(\"start\", None),\n",
    "                \"area_end\": annotation.get(\"area\", {}).get(\"end\", None),\n",
    "                \"category_01\": annotation.get(\"categories\", {}).get(\"category_01\", None),\n",
    "                \"category_02\": annotation.get(\"categories\", {}).get(\"category_02\", None),\n",
    "                \"category_03\": annotation.get(\"categories\", {}).get(\"category_03\", None),\n",
    "                \"decibel\": annotation.get(\"decibel\", None),\n",
    "                \"soundQuality\": annotation.get(\"soundQuality\", None),\n",
    "                \"subCategory\": annotation.get(\"subCategory\", None),\n",
    "            })\n",
    "\n",
    "df_json = pd.DataFrame(json_data)\n",
    "\n",
    "# WAV íŒŒì¼ì—ì„œ MFCC ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
    "def extract_mfcc(file_path, sr=22050, n_mfcc=50):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=sr)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        return np.mean(mfccs, axis=1)  # MFCC í‰ê· ê°’ ë°˜í™˜\n",
    "    except Exception as e:\n",
    "        print(f\"ì˜¤ë¥˜ ë°œìƒ: {file_path} - {e}\")\n",
    "        return [None] * n_mfcc  # ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "\n",
    "wav_data = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        base_name = \"_\".join(file.split(\"_\")[:-1])  # \"_1.wav\" ë¶€ë¶„ ì œê±°í•˜ê³  ê¸°ë³¸ íŒŒì¼ëª… ì¶”ì¶œ\n",
    "        mfcc_features = extract_mfcc(file_path)\n",
    "\n",
    "        wav_data.append({\n",
    "            \"baseName\": base_name,  # JSONê³¼ ë§¤ì¹­í•  ê¸°ë³¸ íŒŒì¼ëª… ì €ì¥\n",
    "            **{f\"mfcc_{i+1}\": mfcc for i, mfcc in enumerate(mfcc_features)}\n",
    "        })\n",
    "\n",
    "df_wav = pd.DataFrame(wav_data)\n",
    "\n",
    "# # JSON ë°ì´í„°ì™€ WAV ë°ì´í„° ë³‘í•© (baseName ê¸°ì¤€)\n",
    "df_etc = pd.merge(df_json, df_wav, on=\"baseName\", how=\"left\").drop(columns=[\"baseName\"])\n",
    "\n",
    "# # ê¸°ì¡´ ë°ì´í„°í”„ë ˆì„ df_combinedì— ì¶”ê°€\n",
    "df_combined2 = pd.concat([df_combined, df_etc], ignore_index=True)\n",
    "\n",
    "# # ê²°ê³¼ í™•ì¸\n",
    "# print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c0155a-24f7-4b31-a45a-6a8260e7850a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ê²°ê³¼: [ 2 -1  1 ...  4  0  3]\n",
      "âœ… OOD (ê¸°íƒ€ ì†ŒìŒ) ì˜ˆì¸¡ ê²°ê³¼ (Softmax ê¸°ë°˜ í•„í„°ë§): [ 1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ 4ï¸âƒ£ OOD ë°ì´í„° ë¡œë“œ & ì „ì²˜ë¦¬ (MFCC íŠ¹ì§• ì‚¬ìš©)\n",
    "ood_X_test = df_etc.iloc[:, -50:]  # OOD ë°ì´í„°ì˜ MFCC 13ê°œ ì»¬ëŸ¼ ì‚¬ìš©\n",
    "\n",
    "# ğŸ“Œ 5ï¸âƒ£ Softmax ê¸°ë°˜ OOD íƒì§€ í•¨ìˆ˜\n",
    "def predict_with_ood_detection(model, X, threshold=0.6):\n",
    "    probs = model.predict_proba(X)  # Softmax í™•ë¥  ì¶œë ¥\n",
    "    max_probs = np.max(probs, axis=1)  # ê°€ì¥ ë†’ì€ í™•ë¥  ê°’\n",
    "    preds = np.argmax(probs, axis=1)  # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤\n",
    "\n",
    "    # íŠ¹ì • í™•ë¥ (threshold) ì´í•˜ì´ë©´ \"ê¸°íƒ€ ì†ŒìŒ\"(-1)ìœ¼ë¡œ ë³€ê²½\n",
    "    final_preds = np.where(max_probs < threshold, -1, preds)\n",
    "    \n",
    "    return final_preds\n",
    "\n",
    "# ğŸ“Œ 6ï¸âƒ£ OOD íƒì§€ ì ìš© (í…ŒìŠ¤íŠ¸ ë°ì´í„° & ê¸°íƒ€ ì†ŒìŒ ë°ì´í„°)\n",
    "y_pred_test = predict_with_ood_detection(model, X_test, threshold=0.8)\n",
    "y_pred_ood = predict_with_ood_detection(model, ood_X_test, threshold=0.8)\n",
    "\n",
    "# ğŸ“Œ 7ï¸âƒ£ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ê²°ê³¼:\", y_pred_test)\n",
    "print(\"âœ… OOD (ê¸°íƒ€ ì†ŒìŒ) ì˜ˆì¸¡ ê²°ê³¼ (Softmax ê¸°ë°˜ í•„í„°ë§):\", y_pred_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cea29f87-b853-49bb-b341-55db171dde0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 60)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04715eda-aa01-4430-b46f-0ec34109891c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fileName', 'labelName', 'area_start', 'area_end', 'category_01',\n",
       "       'category_02', 'category_03', 'decibel', 'soundQuality', 'subCategory',\n",
       "       'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7',\n",
       "       'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13',\n",
       "       'mfcc_14', 'mfcc_15', 'mfcc_16', 'mfcc_17', 'mfcc_18', 'mfcc_19',\n",
       "       'mfcc_20', 'mfcc_21', 'mfcc_22', 'mfcc_23', 'mfcc_24', 'mfcc_25',\n",
       "       'mfcc_26', 'mfcc_27', 'mfcc_28', 'mfcc_29', 'mfcc_30', 'mfcc_31',\n",
       "       'mfcc_32', 'mfcc_33', 'mfcc_34', 'mfcc_35', 'mfcc_36', 'mfcc_37',\n",
       "       'mfcc_38', 'mfcc_39', 'mfcc_40', 'mfcc_41', 'mfcc_42', 'mfcc_43',\n",
       "       'mfcc_44', 'mfcc_45', 'mfcc_46', 'mfcc_47', 'mfcc_48', 'mfcc_49',\n",
       "       'mfcc_50'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73cb519d-9256-4535-9055-679cc182275d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16156, 82)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50658fe9-ad16-4dc7-91a3-91a233d85075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fileName', 'labelName', 'area_start', 'area_end', 'category_01',\n",
       "       'category_02', 'category_03', 'decibel', 'soundQuality', 'subCategory',\n",
       "       'bitRate', 'duration', 'fileFormat', 'fileSize', 'recodingType',\n",
       "       'sampleRate', 'acqDevice', 'acqMethod', 'acqType', 'areaUse',\n",
       "       'dayNight', 'direction', 'distance', 'district', 'latitude',\n",
       "       'longitude', 'micClass', 'obstacle', 'place', 'recordingTime', 'urban',\n",
       "       'weather', 'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6',\n",
       "       'mfcc_7', 'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12',\n",
       "       'mfcc_13', 'mfcc_14', 'mfcc_15', 'mfcc_16', 'mfcc_17', 'mfcc_18',\n",
       "       'mfcc_19', 'mfcc_20', 'mfcc_21', 'mfcc_22', 'mfcc_23', 'mfcc_24',\n",
       "       'mfcc_25', 'mfcc_26', 'mfcc_27', 'mfcc_28', 'mfcc_29', 'mfcc_30',\n",
       "       'mfcc_31', 'mfcc_32', 'mfcc_33', 'mfcc_34', 'mfcc_35', 'mfcc_36',\n",
       "       'mfcc_37', 'mfcc_38', 'mfcc_39', 'mfcc_40', 'mfcc_41', 'mfcc_42',\n",
       "       'mfcc_43', 'mfcc_44', 'mfcc_45', 'mfcc_46', 'mfcc_47', 'mfcc_48',\n",
       "       'mfcc_49', 'mfcc_50'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72069b51-f47e-47c7-8a59-05528789e6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c9e76ca-cd73-4a20-8bc5-de73e72ab703",
   "metadata": {},
   "source": [
    "# df_etc2 ê¸°íƒ€ ì†ŒìŒ (ë™ë¬¼) í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04571192-a643-4538-a1e8-bdf29e27f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = \"/home/ubuntu/data/etc_noise_data_test_02\"\n",
    "\n",
    "# ê¸°ì¡´ ë°ì´í„°í”„ë ˆì„ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "try:\n",
    "    df_combined\n",
    "except NameError:\n",
    "    df_combined = pd.DataFrame()  # ì—†ìœ¼ë©´ ë¹ˆ ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "\n",
    "json_data = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".json\"):\n",
    "        with open(os.path.join(data_dir, file), \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "            annotations = data.get(\"annotations\", [])\n",
    "            annotation = annotations[0] if annotations and isinstance(annotations, list) else {}\n",
    "\n",
    "            # JSON íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°\n",
    "            base_name = os.path.splitext(file)[0]\n",
    "\n",
    "            json_data.append({\n",
    "                \"baseName\": base_name,  # í™•ì¥ì ì—†ëŠ” íŒŒì¼ëª… ì €ì¥\n",
    "                \"fileName\": data[\"audio\"][\"fileName\"],\n",
    "                \"labelName\": annotation.get(\"labelName\", None),\n",
    "                \"area_start\": annotation.get(\"area\", {}).get(\"start\", None),\n",
    "                \"area_end\": annotation.get(\"area\", {}).get(\"end\", None),\n",
    "                \"category_01\": annotation.get(\"categories\", {}).get(\"category_01\", None),\n",
    "                \"category_02\": annotation.get(\"categories\", {}).get(\"category_02\", None),\n",
    "                \"category_03\": annotation.get(\"categories\", {}).get(\"category_03\", None),\n",
    "                \"decibel\": annotation.get(\"decibel\", None),\n",
    "                \"soundQuality\": annotation.get(\"soundQuality\", None),\n",
    "                \"subCategory\": annotation.get(\"subCategory\", None),\n",
    "            })\n",
    "\n",
    "df_json = pd.DataFrame(json_data)\n",
    "\n",
    "# WAV íŒŒì¼ì—ì„œ MFCC ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
    "def extract_mfcc(file_path, sr=22050, n_mfcc=50):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=sr)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        return np.mean(mfccs, axis=1)  # MFCC í‰ê· ê°’ ë°˜í™˜\n",
    "    except Exception as e:\n",
    "        print(f\"ì˜¤ë¥˜ ë°œìƒ: {file_path} - {e}\")\n",
    "        return [None] * n_mfcc  # ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "\n",
    "wav_data = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        base_name = \"_\".join(file.split(\"_\")[:-1])  # \"_1.wav\" ë¶€ë¶„ ì œê±°í•˜ê³  ê¸°ë³¸ íŒŒì¼ëª… ì¶”ì¶œ\n",
    "        mfcc_features = extract_mfcc(file_path)\n",
    "\n",
    "        wav_data.append({\n",
    "            \"baseName\": base_name,  # JSONê³¼ ë§¤ì¹­í•  ê¸°ë³¸ íŒŒì¼ëª… ì €ì¥\n",
    "            **{f\"mfcc_{i+1}\": mfcc for i, mfcc in enumerate(mfcc_features)}\n",
    "        })\n",
    "\n",
    "df_wav = pd.DataFrame(wav_data)\n",
    "\n",
    "# # JSON ë°ì´í„°ì™€ WAV ë°ì´í„° ë³‘í•© (baseName ê¸°ì¤€)\n",
    "df_etc2 = pd.merge(df_json, df_wav, on=\"baseName\", how=\"left\").drop(columns=[\"baseName\"])\n",
    "\n",
    "# # ê¸°ì¡´ ë°ì´í„°í”„ë ˆì„ df_combinedì— ì¶”ê°€\n",
    "#df_combined2 = pd.concat([df_combined, df_etc2], ignore_index=True)\n",
    "\n",
    "# # ê²°ê³¼ í™•ì¸\n",
    "# print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b65a510a-a777-4dbd-9d82-f266571787b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fileName', 'labelName', 'area_start', 'area_end', 'category_01',\n",
       "       'category_02', 'category_03', 'decibel', 'soundQuality', 'subCategory',\n",
       "       'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7',\n",
       "       'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13',\n",
       "       'mfcc_14', 'mfcc_15', 'mfcc_16', 'mfcc_17', 'mfcc_18', 'mfcc_19',\n",
       "       'mfcc_20', 'mfcc_21', 'mfcc_22', 'mfcc_23', 'mfcc_24', 'mfcc_25',\n",
       "       'mfcc_26', 'mfcc_27', 'mfcc_28', 'mfcc_29', 'mfcc_30', 'mfcc_31',\n",
       "       'mfcc_32', 'mfcc_33', 'mfcc_34', 'mfcc_35', 'mfcc_36', 'mfcc_37',\n",
       "       'mfcc_38', 'mfcc_39', 'mfcc_40', 'mfcc_41', 'mfcc_42', 'mfcc_43',\n",
       "       'mfcc_44', 'mfcc_45', 'mfcc_46', 'mfcc_47', 'mfcc_48', 'mfcc_49',\n",
       "       'mfcc_50'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etc2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11906ee6-67d2-4681-9acf-e6fa7d23efdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7.ë™ë¬¼_9206.wav', '7.ë™ë¬¼_9095.wav', '7.ë™ë¬¼_9041.wav', '7.ë™ë¬¼_9203.wav', '7.ë™ë¬¼_9208.wav', '7.ë™ë¬¼_9204.wav', '7.ë™ë¬¼_9110.wav', '7.ë™ë¬¼_8962.wav', '7.ë™ë¬¼_9211.wav', '7.ë™ë¬¼_8979.wav', '7.ë™ë¬¼_9215.wav', '7.ë™ë¬¼_9040.wav', '7.ë™ë¬¼_9090.wav', '7.ë™ë¬¼_9112.wav', '7.ë™ë¬¼_9063.wav', '7.ë™ë¬¼_8954.wav', '7.ë™ë¬¼_9214.wav', '7.ë™ë¬¼_9205.wav', '7.ë™ë¬¼_9213.wav', '7.ë™ë¬¼_9207.wav']\n"
     ]
    }
   ],
   "source": [
    "file_names = df_etc2[\"fileName\"].tolist()\n",
    "print(file_names)  # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe283104-d649-4e27-be1f-99b73fb6b2a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2fdaa6a1e0ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# ğŸ“Œ 6ï¸âƒ£ OOD íƒì§€ ì ìš© (í…ŒìŠ¤íŠ¸ ë°ì´í„° & ê¸°íƒ€ ì†ŒìŒ ë°ì´í„°)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_ood_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0my_pred_ood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_ood_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mood_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-2fdaa6a1e0ba>\u001b[0m in \u001b[0;36mpredict_with_ood_detection\u001b[0;34m(model, X, threshold)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ğŸ“Œ 5ï¸âƒ£ Softmax ê¸°ë°˜ OOD íƒì§€ í•¨ìˆ˜\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_with_ood_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Softmax í™•ë¥  ì¶œë ¥\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmax_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ê°€ì¥ ë†’ì€ í™•ë¥  ê°’\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    995\u001b[0m                       pred_leaf=False, pred_contrib=False, **kwargs):\n\u001b[1;32m    996\u001b[0m         \u001b[0;34m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mraw_score\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    802\u001b[0m                              f\"input n_features is {n_features}\")\n\u001b[1;32m    803\u001b[0m         return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n\u001b[0;32m--> 804\u001b[0;31m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     predict.__doc__ = _lgbmmodel_doc_predict.format(\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[1;32m   3538\u001b[0m         return predictor.predict(data, start_iteration, num_iteration,\n\u001b[1;32m   3539\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3540\u001b[0;31m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[1;32m   3541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[0;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m     def __create_sparse_native(self, cs, out_shape, out_ptr_indptr, out_ptr_indices, out_ptr_data,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[0;34m(mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_num_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m    921\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_preds\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mout_num_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length for predict results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ 4ï¸âƒ£ OOD ë°ì´í„° ë¡œë“œ & ì „ì²˜ë¦¬ (MFCC íŠ¹ì§• ì‚¬ìš©)\n",
    "ood_X_test = df_etc2.iloc[:, -50:]  # OOD ë°ì´í„°ì˜ MFCC 13ê°œ ì»¬ëŸ¼ ì‚¬ìš©\n",
    "\n",
    "# ğŸ“Œ 5ï¸âƒ£ Softmax ê¸°ë°˜ OOD íƒì§€ í•¨ìˆ˜\n",
    "def predict_with_ood_detection(model, X, threshold=0.6):\n",
    "    probs = model.predict_proba(X)  # Softmax í™•ë¥  ì¶œë ¥\n",
    "    max_probs = np.max(probs, axis=1)  # ê°€ì¥ ë†’ì€ í™•ë¥  ê°’\n",
    "    preds = np.argmax(probs, axis=1)  # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤\n",
    "\n",
    "    # íŠ¹ì • í™•ë¥ (threshold) ì´í•˜ì´ë©´ \"ê¸°íƒ€ ì†ŒìŒ\"(-1)ìœ¼ë¡œ ë³€ê²½\n",
    "    final_preds = np.where(max_probs < threshold, -1, preds)\n",
    "    \n",
    "    return final_preds\n",
    "\n",
    "# ğŸ“Œ 6ï¸âƒ£ OOD íƒì§€ ì ìš© (í…ŒìŠ¤íŠ¸ ë°ì´í„° & ê¸°íƒ€ ì†ŒìŒ ë°ì´í„°)\n",
    "y_pred_test = predict_with_ood_detection(model, X_test, threshold=0.8)\n",
    "y_pred_ood = predict_with_ood_detection(model, ood_X_test, threshold=0.8)\n",
    "\n",
    "# ğŸ“Œ 7ï¸âƒ£ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ê²°ê³¼:\", y_pred_test)\n",
    "print(\"âœ… OOD (ê¸°íƒ€ ì†ŒìŒ) ì˜ˆì¸¡ ê²°ê³¼ (Softmax ê¸°ë°˜ í•„í„°ë§):\", y_pred_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b0adc-c8b8-4406-ab7a-f0f0cd1ae31f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1406f486-6e5e-4429-b6db-0d7630ebebce",
   "metadata": {},
   "source": [
    "# df_etc3 ê¸°íƒ€ ì†ŒìŒ (df_etc1 + df_etc2) í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "835bf543-f01a-4937-be09-f390f3c45b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = \"/home/ubuntu/data/etc_noise_data_test_03\"\n",
    "\n",
    "# ê¸°ì¡´ ë°ì´í„°í”„ë ˆì„ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "try:\n",
    "    df_combined\n",
    "except NameError:\n",
    "    df_combined = pd.DataFrame()  # ì—†ìœ¼ë©´ ë¹ˆ ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "\n",
    "json_data = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".json\"):\n",
    "        with open(os.path.join(data_dir, file), \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "            annotations = data.get(\"annotations\", [])\n",
    "            annotation = annotations[0] if annotations and isinstance(annotations, list) else {}\n",
    "\n",
    "            # JSON íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°\n",
    "            base_name = os.path.splitext(file)[0]\n",
    "\n",
    "            json_data.append({\n",
    "                \"baseName\": base_name,  # í™•ì¥ì ì—†ëŠ” íŒŒì¼ëª… ì €ì¥\n",
    "                \"fileName\": data[\"audio\"][\"fileName\"],\n",
    "                \"labelName\": annotation.get(\"labelName\", None),\n",
    "                \"area_start\": annotation.get(\"area\", {}).get(\"start\", None),\n",
    "                \"area_end\": annotation.get(\"area\", {}).get(\"end\", None),\n",
    "                \"category_01\": annotation.get(\"categories\", {}).get(\"category_01\", None),\n",
    "                \"category_02\": annotation.get(\"categories\", {}).get(\"category_02\", None),\n",
    "                \"category_03\": annotation.get(\"categories\", {}).get(\"category_03\", None),\n",
    "                \"decibel\": annotation.get(\"decibel\", None),\n",
    "                \"soundQuality\": annotation.get(\"soundQuality\", None),\n",
    "                \"subCategory\": annotation.get(\"subCategory\", None),\n",
    "            })\n",
    "\n",
    "df_json = pd.DataFrame(json_data)\n",
    "\n",
    "# WAV íŒŒì¼ì—ì„œ MFCC ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
    "def extract_mfcc(file_path, sr=22050, n_mfcc=50):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=sr)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        return np.mean(mfccs, axis=1)  # MFCC í‰ê· ê°’ ë°˜í™˜\n",
    "    except Exception as e:\n",
    "        print(f\"ì˜¤ë¥˜ ë°œìƒ: {file_path} - {e}\")\n",
    "        return [None] * n_mfcc  # ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "\n",
    "wav_data = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        base_name = \"_\".join(file.split(\"_\")[:-1])  # \"_1.wav\" ë¶€ë¶„ ì œê±°í•˜ê³  ê¸°ë³¸ íŒŒì¼ëª… ì¶”ì¶œ\n",
    "        mfcc_features = extract_mfcc(file_path)\n",
    "\n",
    "        wav_data.append({\n",
    "            \"baseName\": base_name,  # JSONê³¼ ë§¤ì¹­í•  ê¸°ë³¸ íŒŒì¼ëª… ì €ì¥\n",
    "            **{f\"mfcc_{i+1}\": mfcc for i, mfcc in enumerate(mfcc_features)}\n",
    "        })\n",
    "\n",
    "df_wav = pd.DataFrame(wav_data)\n",
    "\n",
    "# # JSON ë°ì´í„°ì™€ WAV ë°ì´í„° ë³‘í•© (baseName ê¸°ì¤€)\n",
    "df_etc3 = pd.merge(df_json, df_wav, on=\"baseName\", how=\"left\").drop(columns=[\"baseName\"])\n",
    "\n",
    "# # ê¸°ì¡´ ë°ì´í„°í”„ë ˆì„ df_combinedì— ì¶”ê°€\n",
    "#df_combined2 = pd.concat([df_combined, df_etc2], ignore_index=True)\n",
    "\n",
    "# # ê²°ê³¼ í™•ì¸\n",
    "# print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8719e48-ed3c-4080-959d-3fb3c9c4f797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 60)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etc3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9c23569-054a-4f2e-9809-6db00d30145d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7.ë™ë¬¼_9206.wav', '7.ë™ë¬¼_9095.wav', '7.ë™ë¬¼_9041.wav', '3.í•­ê³µê¸°_3089.wav', '3.í•­ê³µê¸°_3096.wav', '7.ë™ë¬¼_9203.wav', '4.ì—´ì°¨_3548.wav', '7.ë™ë¬¼_9208.wav', '7.ë™ë¬¼_9204.wav', '7.ë™ë¬¼_9110.wav', '3.í•­ê³µê¸°_65672.wav', '7.ë™ë¬¼_8962.wav', '3.í•­ê³µê¸°_19365.wav', '7.ë™ë¬¼_9211.wav', '3.í•­ê³µê¸°_3090.wav', '4.ì—´ì°¨_3551.wav', '7.ë™ë¬¼_8979.wav', '3.í•­ê³µê¸°_65674.wav', '4.ì—´ì°¨_3807.wav', '7.ë™ë¬¼_9215.wav', '4.ì—´ì°¨_3806.wav', '7.ë™ë¬¼_9040.wav', '4.ì—´ì°¨_3554.wav', '3.í•­ê³µê¸°_65671.wav', '7.ë™ë¬¼_9090.wav', '7.ë™ë¬¼_9112.wav', '3.í•­ê³µê¸°_3093.wav', '3.í•­ê³µê¸°_65673.wav', '7.ë™ë¬¼_9063.wav', '4.ì—´ì°¨_3810.wav', '4.ì—´ì°¨_3552.wav', '4.ì—´ì°¨_3808.wav', '7.ë™ë¬¼_8954.wav', '3.í•­ê³µê¸°_3092.wav', '7.ë™ë¬¼_9214.wav', '7.ë™ë¬¼_9205.wav', '4.ì—´ì°¨_3809.wav', '7.ë™ë¬¼_9213.wav', '7.ë™ë¬¼_9207.wav', '4.ì—´ì°¨_3547.wav']\n"
     ]
    }
   ],
   "source": [
    "file_names = df_etc3[\"fileName\"].tolist()\n",
    "print(file_names)  # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "724e2f23-453a-4d6c-ac91-ed77ade6b345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ OOD (ê¸°íƒ€ ì†ŒìŒ) ì˜ˆì¸¡ ê²°ê³¼ (Softmax ê¸°ë°˜ í•„í„°ë§)\n",
      "        fileName  predicted_label\n",
      "   7.ë™ë¬¼_9206.wav                1\n",
      "   7.ë™ë¬¼_9095.wav                1\n",
      "   7.ë™ë¬¼_9041.wav                1\n",
      "  3.í•­ê³µê¸°_3089.wav                1\n",
      "  3.í•­ê³µê¸°_3096.wav                1\n",
      "   7.ë™ë¬¼_9203.wav                1\n",
      "   4.ì—´ì°¨_3548.wav                1\n",
      "   7.ë™ë¬¼_9208.wav                1\n",
      "   7.ë™ë¬¼_9204.wav                1\n",
      "   7.ë™ë¬¼_9110.wav                1\n",
      " 3.í•­ê³µê¸°_65672.wav                1\n",
      "   7.ë™ë¬¼_8962.wav                1\n",
      " 3.í•­ê³µê¸°_19365.wav                1\n",
      "   7.ë™ë¬¼_9211.wav                1\n",
      "  3.í•­ê³µê¸°_3090.wav                1\n",
      "   4.ì—´ì°¨_3551.wav                1\n",
      "   7.ë™ë¬¼_8979.wav               -1\n",
      " 3.í•­ê³µê¸°_65674.wav               -1\n",
      "   4.ì—´ì°¨_3807.wav                1\n",
      "   7.ë™ë¬¼_9215.wav                1\n",
      "   4.ì—´ì°¨_3806.wav                1\n",
      "   7.ë™ë¬¼_9040.wav                1\n",
      "   4.ì—´ì°¨_3554.wav                1\n",
      " 3.í•­ê³µê¸°_65671.wav                1\n",
      "   7.ë™ë¬¼_9090.wav                1\n",
      "   7.ë™ë¬¼_9112.wav               -1\n",
      "  3.í•­ê³µê¸°_3093.wav                1\n",
      " 3.í•­ê³µê¸°_65673.wav                1\n",
      "   7.ë™ë¬¼_9063.wav               -1\n",
      "   4.ì—´ì°¨_3810.wav                1\n",
      "   4.ì—´ì°¨_3552.wav                1\n",
      "   4.ì—´ì°¨_3808.wav                1\n",
      "   7.ë™ë¬¼_8954.wav               -1\n",
      "  3.í•­ê³µê¸°_3092.wav                1\n",
      "   7.ë™ë¬¼_9214.wav                1\n",
      "   7.ë™ë¬¼_9205.wav                1\n",
      "   4.ì—´ì°¨_3809.wav                1\n",
      "   7.ë™ë¬¼_9213.wav                1\n",
      "   7.ë™ë¬¼_9207.wav                1\n",
      "   4.ì—´ì°¨_3547.wav                1\n",
      "\n",
      "âœ… OOD ë°ì´í„°ì—ì„œ -1 ê°œìˆ˜: 5\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ 4ï¸âƒ£ OOD ë°ì´í„° ë¡œë“œ & ì „ì²˜ë¦¬ (MFCC íŠ¹ì§• ì‚¬ìš©)\n",
    "ood_X_test = df_etc3.iloc[:, -50:]  # OOD ë°ì´í„°ì˜ MFCC 13ê°œ ì»¬ëŸ¼ ì‚¬ìš©\n",
    "\n",
    "# ğŸ“Œ 5ï¸âƒ£ Softmax ê¸°ë°˜ OOD íƒì§€ í•¨ìˆ˜\n",
    "def predict_with_ood_detection(model, X, threshold=0.6):\n",
    "    probs = model.predict_proba(X)  # Softmax í™•ë¥  ì¶œë ¥\n",
    "    max_probs = np.max(probs, axis=1)  # ê°€ì¥ ë†’ì€ í™•ë¥  ê°’\n",
    "    preds = np.argmax(probs, axis=1)  # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤\n",
    "\n",
    "    # íŠ¹ì • í™•ë¥ (threshold) ì´í•˜ì´ë©´ \"ê¸°íƒ€ ì†ŒìŒ\"(-1)ìœ¼ë¡œ ë³€ê²½\n",
    "    final_preds = np.where(max_probs < threshold, -1, preds)\n",
    "    \n",
    "    return final_preds\n",
    "\n",
    "# ğŸ“Œ 6ï¸âƒ£ OOD íƒì§€ ì ìš© (ê¸°íƒ€ ì†ŒìŒ ë°ì´í„°)\n",
    "y_pred_ood = predict_with_ood_detection(model, ood_X_test, threshold=0.8)\n",
    "\n",
    "# âœ… ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€í•˜ì—¬ íŒŒì¼ëª…ê³¼ í•¨ê»˜ ì¶œë ¥\n",
    "df_etc3[\"predicted_label\"] = y_pred_ood\n",
    "\n",
    "# âœ… ê¸°íƒ€ ì†ŒìŒ(-1) ê°œìˆ˜ ì¹´ìš´íŠ¸\n",
    "num_neg1_ood = np.count_nonzero(y_pred_ood == -1)\n",
    "\n",
    "# âœ… ì¶œë ¥ ì •ë¦¬ (íŒŒì¼ëª… + ì˜ˆì¸¡ ê²°ê³¼)\n",
    "print(\"\\nğŸ“Œ OOD (ê¸°íƒ€ ì†ŒìŒ) ì˜ˆì¸¡ ê²°ê³¼ (Softmax ê¸°ë°˜ í•„í„°ë§)\")\n",
    "print(df_etc3[[\"fileName\", \"predicted_label\"]].to_string(index=False))\n",
    "\n",
    "# âœ… ê¸°íƒ€ ì†ŒìŒ(-1) ê°œìˆ˜ ì¶œë ¥\n",
    "print(f\"\\nâœ… OOD ë°ì´í„°ì—ì„œ -1 ê°œìˆ˜: {num_neg1_ood}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d2fb5-d606-4adb-a995-b17edd059281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fc9311-0d61-4674-8412-39c0dc4864d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b1eadd-bf8c-4791-8d8d-a30cc2b948c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7849a9cd-e90d-442e-9afa-4f607ede619e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 2479.2185\n",
      "Epoch [20/50], Loss: 2366.5955\n",
      "Epoch [30/50], Loss: 2171.6387\n",
      "Epoch [40/50], Loss: 1816.7802\n",
      "Epoch [50/50], Loss: 1286.7799\n",
      "OOD íƒì§€ ê²°ê³¼: [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-49949fc6a0a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mlgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mlgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_reduced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_reduced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    970\u001b[0m                     \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m                     callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    973\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0minit_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m         )\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    290\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3021\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3023\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   3024\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# ğŸ“Œ 1ï¸âƒ£ Autoencoder ëª¨ë¸ ì •ì˜\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=16):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, input_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# ğŸ“Œ 2ï¸âƒ£ ë°ì´í„° ì¤€ë¹„\n",
    "X = df_combined.iloc[:, -50:].values  # MFCC 50ê°œ íŠ¹ì„± ì‚¬ìš©\n",
    "y = df_combined['category_03'].astype('category').cat.codes.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PyTorch Tensor ë³€í™˜\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# ğŸ“Œ 3ï¸âƒ£ Autoencoder í•™ìŠµ\n",
    "input_dim = X_train.shape[1]\n",
    "latent_dim = 16  # ì••ì¶•í•  ì°¨ì› ì„¤ì •\n",
    "model = Autoencoder(input_dim, latent_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# í•™ìŠµ ê³¼ì •\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train_tensor)\n",
    "    loss = criterion(output, X_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# ğŸ“Œ 4ï¸âƒ£ OOD íƒì§€ - ì¬êµ¬ì„± ì˜¤ì°¨ ê³„ì‚°\n",
    "model.eval()\n",
    "def detect_ood(X, threshold=0.05):\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        reconstructed = model(X_tensor)\n",
    "    loss = torch.mean((X_tensor - reconstructed) ** 2, axis=1).cpu().numpy()\n",
    "    return np.where(loss > threshold, -1, 1)  # ì„ê³„ê°’ë³´ë‹¤ í¬ë©´ OOD\n",
    "\n",
    "# OOD íƒì§€ ì ìš©\n",
    "ood_labels = detect_ood(ood_X_test.values, threshold=0.05)\n",
    "print(\"OOD íƒì§€ ê²°ê³¼:\", ood_labels)\n",
    "\n",
    "# ğŸ“Œ 5ï¸âƒ£ ì°¨ì› ì¶•ì†Œëœ ë°ì´í„°ë¡œ LightGBM í•™ìŠµ\n",
    "with torch.no_grad():\n",
    "    X_train_reduced = model.encoder(X_train_tensor).cpu().numpy()\n",
    "    X_test_reduced = model.encoder(X_test_tensor).cpu().numpy()\n",
    "\n",
    "lgbm = LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "lgbm.fit(X_train_reduced, y_train)\n",
    "y_pred = lgbm.predict(X_test_reduced)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"LightGBM ì •í™•ë„ (Autoencoder ì°¨ì› ì¶•ì†Œ ì ìš©): {acc:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba6d52d-6925-4d15-a9da-ef19b0ff4cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ff36022-0dba-4eaf-b212-e7a6f6404982",
   "metadata": {},
   "source": [
    "# df_combined2 (df_combined + df_etc) ëª¨ë¸ ìƒì„± í›„ ì„±ëŠ¥ ì²´í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4769058-811b-47da-9f25-9083dbe5cc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "LightGBM ì •í™•ë„: 0.8313\n",
      "\n",
      "Confusion Matrix:\n",
      "        ê¸°ì°¨  ë¹„í–‰ê¸°  ì´ë¥œì°¨ê²½ì   ì´ë¥œì°¨ì£¼í–‰ìŒ  ì§€í•˜ì²   ì°¨ëŸ‰ê²½ì   ì°¨ëŸ‰ì‚¬ì´ë Œ  ì°¨ëŸ‰ì£¼í–‰ìŒ  í—¬ë¦¬ì½¥í„°\n",
      "ê¸°ì°¨       0    0      0       0    0     0      0      0     0\n",
      "ë¹„í–‰ê¸°      0    0      0       2    0     0      0      0     0\n",
      "ì´ë¥œì°¨ê²½ì     0    1    845      13    1    75      8      6     0\n",
      "ì´ë¥œì°¨ì£¼í–‰ìŒ   8    8     11     760    3    28     25     77     0\n",
      "ì§€í•˜ì²       0    0      0       1    0     0      0      0     0\n",
      "ì°¨ëŸ‰ê²½ì      2    0     54      32    1   495     17     20     0\n",
      "ì°¨ëŸ‰ì‚¬ì´ë Œ    0    2      5      15    0    21    352     18     0\n",
      "ì°¨ëŸ‰ì£¼í–‰ìŒ    2    0      3      67    1     8     10    238     0\n",
      "í—¬ë¦¬ì½¥í„°     0    0      0       0    0     1      0      0     0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ê¸°ì°¨       0.00      0.00      0.00         0\n",
      "         ë¹„í–‰ê¸°       0.00      0.00      0.00         2\n",
      "       ì´ë¥œì°¨ê²½ì        0.92      0.89      0.91       949\n",
      "      ì´ë¥œì°¨ì£¼í–‰ìŒ       0.85      0.83      0.84       920\n",
      "         ì§€í•˜ì²        0.00      0.00      0.00         1\n",
      "        ì°¨ëŸ‰ê²½ì        0.79      0.80      0.79       621\n",
      "       ì°¨ëŸ‰ì‚¬ì´ë Œ       0.85      0.85      0.85       413\n",
      "       ì°¨ëŸ‰ì£¼í–‰ìŒ       0.66      0.72      0.69       329\n",
      "        í—¬ë¦¬ì½¥í„°       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.83      3236\n",
      "   macro avg       0.45      0.45      0.45      3236\n",
      "weighted avg       0.84      0.83      0.84      3236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# ë ˆì´ë¸”(label)ê³¼ í”¼ì²˜(features) ë¶„ë¦¬\n",
    "X = df_combined2.iloc[:, -50:]  # ë§ˆì§€ë§‰ 13ê°œ ì»¬ëŸ¼ì„ íŠ¹ì„±(MFCC)ìœ¼ë¡œ ì‚¬ìš©\n",
    "y = df_combined2['category_03'].astype('category').cat.codes  # ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ë³€í™˜\n",
    "\n",
    "# ë²”ì£¼í˜• ë°ì´í„°(ë ˆì´ë¸”) ìˆ«ìë¡œ ë³€í™˜\n",
    "y = y.astype('category').cat.codes\n",
    "\n",
    "# í´ë˜ìŠ¤ ë ˆì´ë¸” ë§¤í•‘\n",
    "class_labels = df_combined2['category_03'].astype('category').cat.categories\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë¶„í•  (train: 80%, test: 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "num_classes = len(set(y))\n",
    "print(num_classes)\n",
    "    \n",
    "# LightGBM ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "model2 = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=-1, random_state=42)\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "# í‰ê°€ ê²°ê³¼ ì¶œë ¥\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"LightGBM ì •í™•ë„: {acc:.4f}\")\n",
    "\n",
    "# í˜¼ë™ í–‰ë ¬ ë° ë¶„ë¥˜ ë³´ê³ ì„œ ì¶œë ¥\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred), index=class_labels, columns=class_labels)\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_labels.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4500a507-b115-4e7e-a70f-b9b9f59ffd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OOD (ê¸°íƒ€ ì†ŒìŒ) ì˜ˆì¸¡ ê²°ê³¼ (Softmax ê¸°ë°˜ í•„í„°ë§): [ 5  0  3  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  6  5  5  5  5  5  5  5  5  2  5  5  5  5  5  5  5  5\n",
      "  5  2  2  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  3  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  2  5  5  5  5  5  5  3  5  5  5  5  5  5  3  5  5  5  0  5  2  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  2  2  5  5  5  5  5  5  5  2  2  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  2  5  2  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  2  5  5  2  5  5  5  5  5  5  0  0  0  5  5  2  2  2  2\n",
      "  2  5  5  5  5  5  5  5  5  5  2  0  5  2  2  5  5  2  5  0  5  5  5  5\n",
      "  5  5  2  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  6  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  0  5  5  5  5  5  5  5  2  2  2  2  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  2  5  2  5  5  5  2  2  5  5  5  5  5  5  5  5  5\n",
      "  2  2  2  2  2  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  2  5  5  5\n",
      "  5  5  5  5  5  5  2  5  5  5  5  5  5  5  2  5  5  5  5  5  2  5  5  5\n",
      "  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  0  0  0  5  2  5  5  5  5  5  0  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  2  5  5  5  5  5  5  5\n",
      "  2  2  5  5  5  5  5  1  5  5  5  5 -1  0  0 -1  5  5  2  5  5  5  5  5\n",
      " -1  5  5  5  5  5  5  2  5  5  2 -1  5  2  7  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  5  5  5  5  5  5  5  5  2\n",
      "  5  5  5  5  5  5  5  5 -1  5  5  5  5  5  5  5  5  5  5 -1  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  5  5  5  3  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  1  5  5  5  5  6 -1  5  2  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  7  2  5  5  5  5  5  5  5  2  5  6  5  5  5  1\n",
      "  5  5  5  5  5  5  5  5  5  5  5  3  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  3  5  5  5  5  5  5  5  5  5  2  5  5  5  5  3  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  2  5  5  5  5  5  5  5  5  5  2  5  5  5  5  2  5  5  5  5  5  5  2  5\n",
      "  5  2  5  5  5  5  1  5  5  5  5  5  5  3  5  5  5  5  2  2  2  5  5  5\n",
      "  5  5  5  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  0  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  2  2  5  2  5  5  2  5  5  5  2  2  2  5  5  5\n",
      "  2  5  5  5  5  5  5  5  2  5  5  2  5  5  5  0  5  2  2  5  5  6  5  5\n",
      "  5  5  5  3  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  2  5  5  5  5  5  5  5  5  5  5  5  3  5  2\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  2  2  5  5  5  5  2  2  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  7  5  5  5  5  5  5  2  5  5  2  5  5\n",
      "  5  5  5  5  2  5  5  5  5  5  5  5  5  2  5  5  5  5  5  5  2  5  5  5\n",
      "  5  2  5  5  2  0  5  5  5  5  5  5  5  5  5  5 -1  6  5  2  5  3  5  6\n",
      "  5  5  5  5  2  5  5  5  5  5  5  5 -1 -1  5  5  2  5  5  5  2  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  2  5  5  5  5  2  5  6  2  0  5  5 -1  3 -1  5  5 -1 -1  7  5  5\n",
      "  5  5  5  5  5  2  7  5  5  5  5 -1  5  5 -1  3  5  5  5 -1  3  5  5  5\n",
      " -1  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5 -1  5  5  2  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  3  0  5  2  0  5  5  5  5  5  5  3  5  5  5  0  0  5\n",
      "  5  5  5  7  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2\n",
      "  5  5  5  5  5  0  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  6  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  2  5  2  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  2  5  2\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  5  5  5  5  2  5\n",
      "  5  5 -1  5  2  7  5  2  2  5  2  5  2  5  5  5  5  5  5  2  5  5  5  3\n",
      "  5  5  7  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  1  5  5\n",
      "  5  5  5  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  3\n",
      "  5  5  5  5  5  5  5  5  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  2  6  5  6  0  5  0  0  5  5  5  2  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  2  5  5  5  6  5  5  5  0  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  6  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  2  5  2  5  5  0  2  5  5  5  2  5  5  5  5  5  5  5\n",
      "  5  5  5  3  5  5  5  5  5  5  5  5  2  7  5  5  5 -1  5  5  5 -1  1  5\n",
      "  5  5  5  5  5  5 -1  5 -1  5  5  5  5  5  5  2  3  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  5  6  3 -1  2  5  3\n",
      "  5  5  5  5  5  5  2  3  2  5 -1  5  5  5  5  5  5  5  5  5  5  2  5  3\n",
      "  3  5  5  2  5  5  5  5  2  5  5  2  5  5  5  5  5  5  2  5  5  5  5  5\n",
      "  5 -1  5  5  2  7  5  5  5  5  5  2  5  5  5  5  5  2  5  5  5  5  5  5\n",
      " -1  2  5  5  5  5  5  5  2  5  5  5  5  2  5  5  7  5  5  5  5  5  5  5\n",
      "  5  2  2  5  5  5 -1  6  5  5  5  5 -1  5 -1  5  5  5  2  5  5  5  5  5\n",
      "  5  3  5  3  2  5  5  5  5  5  5 -1  5  5  5  5  5  5  7  5  5  5  2  5\n",
      "  3  5  5  5  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5 -1\n",
      "  5  5  5  5  5  6  5  5  5  5  3  5  5  5  5  2  5  5  5 -1 -1  5  5  7\n",
      "  2  5  5  5  5  5  5  5  5  5  2  5  5  2  5  5  5  2 -1  5  5  5 -1  5\n",
      "  5  5  2  5  5  5  5  5  5  2  5  5  5 -1  5  5 -1  5  5 -1 -1 -1  5  5\n",
      "  5  5  2  5  5  5  5  3  5  2  5  5  2  5  5  5  5  5  5  5  5  5  7  5\n",
      " -1  5  5  5  5  5 -1  5  5  6  5  2  5  5  5  5  3  5  5  5  5  5  2  7\n",
      "  5  5  2  5  5  5  5  5 -1  5  5  5  5  5  2  5  5  2  5  5 -1  5  3  5\n",
      "  5 -1  5  5  2  5  5  5  5  5  5  5  2  5  5  5 -1  5  5  5  5  5  5  5\n",
      "  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  5  5  5  5  5\n",
      "  5  5  2  5  5  5  5  5 -1 -1  7  2 -1  5  2  5  5  5  5 -1  5  5  3  5\n",
      "  5  5  5  5  2  5 -1  5  5  5  5 -1  5  5  5  6  5 -1 -1  5  5  5  5  5\n",
      "  5 -1  6  5  5  5  2 -1  5  5  5  5  5  5  5  7  2  5  5  5  6  5  5  5\n",
      "  5  5  5  5  5 -1  5  5  2  5  5  2  5  5  5  6  3  3  5  5  5  5  6  5\n",
      "  5 -1 -1  5  5  5  5  5  5  5 -1  5  5  5  5  5  5  5  5  5 -1  5  5  5\n",
      "  5  5  5  5 -1  5  5  5  5  5 -1 -1  5  5  5  5  5  5 -1  5 -1 -1  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  5  3  5  5  1\n",
      "  1  5  5  5 -1  5  5  5  5 -1  5 -1 -1  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  7  5  5  5  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  6  5  5  5 -1  5  5  5  5  5  5  5  5  5  5  5  5  5  5 -1  5  7  5  5\n",
      "  5  5  5  5 -1  5  5  5  5  5  5  5  5  5 -1 -1  2 -1 -1  3 -1  5 -1 -1\n",
      "  5  5  5  5 -1  5  5  5  5  2  5  7  3 -1  5  5 -1  5 -1  5  3  5  5  5\n",
      "  5  3  5  5  2  3  5  5  5  5  5 -1  5  5  5 -1  5  5  5  5  5  5  5  5\n",
      "  5  5  5  6  7  5  5  5  5 -1  3  2  7  5  5  5  5  5 -1  5  7  5 -1  2\n",
      "  5  5 -1  5  5  5  5  5  5  5  5  5 -1  3  5 -1 -1 -1  5  5  5  3  5  5\n",
      "  5  5  5 -1  5  5  3 -1  3  5  6  5  5  5  5  5  5  5  5  5  5  5  6  5\n",
      "  5 -1 -1  2  5  5  5 -1  5  5 -1  5  5  5  5  5  5  5  3  5  5  5  5  5\n",
      "  5 -1 -1 -1  5  5  5  5  5  3  5  3  5  4  6 -1  5  5  5  5  5 -1 -1  5\n",
      "  5  5  5  5  5  5  5  5  5  3 -1  5  5  5 -1  2  6  2 -1  5  5  3  5  5\n",
      " -1  5  5  5  5 -1  7 -1  6  3  5  5  5  5  3  5  5  2  5 -1  5 -1  5  5\n",
      "  5 -1  5  5  5  5  5  5  5 -1 -1  5  5 -1  5  5  5  5 -1 -1  5  5  5  5\n",
      "  7  5  5  5  3  7  5 -1  5  3 -1  5  5 -1  5 -1 -1  5  5  5  5  5  5  5\n",
      "  5  5  5 -1  5  5  5 -1 -1  5 -1  5  5  5  5  5  5  5  5  5  5  6  5  5\n",
      " -1  5  5  5  5 -1 -1  5  7  5  7  5  5  5  5 -1 -1  5  3  5  5  5 -1  5\n",
      "  3 -1  3  5  5  5  5  5  5  5 -1  2  5  5  5  5  2  3  5  2  5  5  5  5\n",
      "  5  5  5  5 -1 -1  5  5  2 -1  5  5  5 -1  5 -1  5  5  3  5  5  6  5  5\n",
      "  5  5  5 -1 -1  5  2  5  5 -1  5 -1  5  5  7  5  5  5  5 -1  5  5 -1  5\n",
      "  5  5  5  5  5  5  5  5 -1  5  5 -1  5  5  5  6  5  5  5  5  3  5  5  5\n",
      "  5  5  5  5  5  5  3  3  5  3  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5 -1  5 -1  5  5  5  5  5  5  5  5  5  5  5 -1 -1  5 -1  5  7 -1  5\n",
      "  5  5  5  5  5  5  5  5  5 -1 -1  3  3 -1  5  5  5 -1  5 -1  5  5  5  5\n",
      "  3  5  5  5  2  5  5  5 -1  5  5  5  5  5  5  6  5  6  5 -1  5  3  5  5\n",
      "  5  5  6  5  5  5  5  5  5  5  5  5 -1 -1  5  7 -1 -1  5  5  5  3  5  5\n",
      "  5  5  5  5  5  5  2  5  5  5  6  5  5  5  5 -1  2 -1  5 -1  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  7  5  5  5  5  5  5  5 -1  5 -1 -1 -1  5  5\n",
      "  5  5  2  5  5  5  5  5 -1  5  5 -1  5  5  2 -1 -1 -1  5  5  5  2  5  3\n",
      "  5 -1  5  5  5  5  5  5  2 -1  5  5  5  5  5  5  5  5  2  5  5  5 -1  5\n",
      "  5  5  5  5  5  5  2  5  5  7  5  5  3  7  3  5  5  5  2  5  5  5  5  2\n",
      " -1  5  5  5  5  5  3  0  5  2  5  5  5  5  5  5  2 -1  5  3  5  6  6  6\n",
      "  6  6  6  6  3 -1  6  6  6  6  6  6 -1  6  6  6  6  6 -1  6  6 -1 -1 -1\n",
      "  6 -1  6  6  6  6  6  6  6  6  6  6 -1  6  6  2  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  5  6  6  6  3  6  6  6  6  6  6  6  6  6  6  6  6  3\n",
      "  6  6  6  6  7  6 -1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6 -1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      " -1  6  6  6  6  6  6  6  6  6  6  6  6  7  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  7  3  6  6 -1  6  6  6  6 -1 -1  3  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  5 -1  6  6  6  6  5  6  6  6  6  6  6  6  6 -1  6  6  6\n",
      "  6  6  5  6  6  6  6  6  6  6  6  6  6  6  6  3  6  6  6  6  6  6  6 -1\n",
      "  6  6  6  7  6  6  5  5  6  6  6  6  6 -1  6  6  6  3  6  6  6  6  7  6\n",
      "  6  1  6  6  6  6  2  6  6  6  6  6  6  6  6  6  6  6  6 -1  6  6 -1  6\n",
      "  6  6  6  6  6  6  6  7  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      " -1  6  3  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 -1  6\n",
      "  6  6  6  6  6  6  6  6 -1  6  6  6  6  6  6  6  6  6  3  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5 -1  3  5  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6 -1  6  6 -1  6  6  6  5  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  6  6  6 -1  6  6  6  6\n",
      "  6  6  6  6  6  5  6  6  6  6  6  7  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  3  6  6  6  6  6  6  6  6 -1  6  5  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  5  2  6  6  6  6 -1  6  6  6  6  6  6  6\n",
      " -1 -1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  6  7  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6 -1  6  3  6  6  6  3  6  6  6  6\n",
      "  6  7  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 -1  3  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6 -1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  6\n",
      "  6  6  6  6  1  6  6  6  6  6  6  6  2  6  6  6  6  6  6  6  6  6  6  6\n",
      "  3  6  6  6  6  6  6  6  6  6  6  6  6  6  6  3  6  6  6  6  6  6  7  6\n",
      "  6  6  6  6  3  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  3  6  6\n",
      "  7  6  6  6 -1  6  6  6  6 -1 -1  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  2  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      " -1  6  6  6  3  6  6  6  6  6  5  5  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  2  2  6  6  6  6  5 -1  6  6 -1  5  6  6  6  6  6  6  6  5  6  6  6\n",
      "  6  6  6  6  6  6  3  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  2  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 -1  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6 -1  6  6  6  6  6  6  6  6  6 -1 -1  6  6  6\n",
      "  6  6  6  6  6 -1 -1  6  6  6  6  6  6  6 -1  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  3  6  6  6  6 -1  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6 -1  6  6  6  6 -1  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  3  6  6  6  6\n",
      "  6  6  6  6  6  5  6  6  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      " -1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 -1\n",
      "  6  5  6  6  6  6  6  6  7  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      " -1  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6  3  6  6  6  6  6  5  6\n",
      "  6  6  6  6  6  6  6  6  3  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  7  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  2  6  5  6  6  6  5  6  6  6  6  6  7  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  2  6  6  6  6  6  6  6  2  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6  6  6  2  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5 -1  6\n",
      "  6  6  6  6  6  6  6  6  3  6  6  6  6  6  6  6  6  6  6 -1  6  6  6  6\n",
      "  6  6  6 -1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  2  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  3  6  6  6  6  6  6  6  6  6  7  6  6  6  6  6  6  5  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6 -1  6  6  6  6  6  6  7  6  6  6  6  6  6  6  5  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 -1  6  6  6  6  6  6  6  6\n",
      "  6  5  6  6  3  6  6  6  6  6  6  6 -1  6 -1  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  3 -1  6  6  6  6  6  6  7  6  6  6  5  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 -1  6  6  6 -1  6\n",
      "  6  6  6  6  6  6 -1  6  6  6  2  6  6  6  6  6  6  6  6 -1  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  3  6  6  6  6  6  5  6\n",
      "  6 -1  6  6  6  6  6  6 -1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6  6  6  6  6  6  6  6  6\n",
      "  6  6 -1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  2  6  6  6  6  6  6  6  1  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6 -1  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  3  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  2  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6 -1 -1  6  6  6  6  5  6  6  6  6  6  6  6  6  6  6  6  7  6\n",
      "  6  6  6  5  6  6  6  6  6  6  6  6  5  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  5  6  6  6  6 -1  6  6  6  6  6  6  6  6  7  3  7  7  7\n",
      " -1  7 -1  7 -1  7  7  7  7  7  7  7  7  7  7  7  7  7  7  3  7  7  3  7\n",
      "  7  7  7 -1  7  7  7  7  7  7  7  7  3  7  7  7  7  2  7  7  7 -1  7  7\n",
      "  3 -1  7  7  7  7  7  7 -1  7  7 -1  7  7  7 -1  7  7  6  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7 -1  7  3  7  7  7  7  7  7  7 -1  7  7  7  7 -1  7\n",
      "  7  3  7  7  7  7  7  7  7  7  7  7  7  3  7  7 -1 -1 -1  7 -1 -1  7  7\n",
      "  7  7  7  3 -1  7  7  3  7  3  3  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7 -1 -1 -1 -1  7  7  7  7  7  7  7  7  7 -1  7  7  3  3  7\n",
      "  7  7  7  7  7  7  3 -1  7  7  7  7  7  7 -1 -1  7  7  7  3  7  7  7  7\n",
      "  7  3  7  7  7  7  7  7  7  3  7  3  7  7  7  3  7  7  7  7 -1 -1  3  7\n",
      "  3  7  7  7 -1 -1  7  7  7  7  3  7  7  7  7  7  3  7  7  7  7  7  7  7\n",
      " -1  7  7  7  7  7  7  7  3  7  3  7  7  7  7  7  7  6  7  7  7  7  7 -1\n",
      "  7  7  7  7  7  7 -1 -1  6  7  7  7  7 -1  7  7  7  3  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7 -1  7  7 -1  7 -1 -1  7  7  7  7  3  7  7  7  7  7  7\n",
      " -1  7  7  7  7  7  7  7  7  6  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  3  3  7  7  7  7  7  7  3  7  7  7  7  7  7  7  7 -1  7  7  7 -1  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7 -1  7  7  7  7  6  7  7  7  7  3  7  7 -1\n",
      "  7  7  7  7 -1  7  7 -1  3  7  7  7  7  7  7  7  3  7  3 -1  7  7  7  7\n",
      "  7  7  7  7  7  3  7 -1  7 -1 -1  7  3  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  3 -1  3  7  7  7  7  7  7  7  7  7 -1  7  7\n",
      "  7  7  7  7  7  7  7 -1  7  7  7  7  7  3  3  3  7 -1  7 -1  7  7  7  7\n",
      "  7  7  7  7 -1  7  7  7  7  7  7  7  7  7  3  7  7  7 -1  7  7  7  7 -1\n",
      "  0  7  7  7  7  7  7  7  7  3  7  7  7  7 -1  7  3  7  7  7  7 -1  7  3\n",
      "  7  7  7  7  7  7  7  7  7  7 -1  7  7 -1  7  7  3  7  7  7 -1  3  7  7\n",
      "  7 -1  7  7  7  7  7  7  7  7  7  7  3  7  7  7  7  7 -1  7  7 -1  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  6  7  6 -1  7  7\n",
      "  3 -1  6  3  7  7  7 -1 -1  7  7  7  7  7 -1  7  7  7  7  7  7 -1 -1  7\n",
      " -1  3 -1  7  7  7  7  3  3  7  7 -1  7  7  7 -1  7  7  3  7  7  7  7  3\n",
      "  7  7  7  7  7  7  7  7  3  7  7  7  7  7 -1  7  6  7  7  7  7 -1 -1 -1\n",
      "  7  7 -1  7  7  7  7  7  7  7  7  7  7 -1  7  7  7  7  7  7  7  7  7  3\n",
      "  6  3  7  7 -1  7  7  7  7  7  3  7  7  7  7  3  7  7  7 -1  7  7 -1  7\n",
      "  7  7  7  7  7  3 -1  3  7  7 -1  7  7 -1  7  7  7  7  7 -1 -1  3  7 -1\n",
      "  3 -1  7  7  7  7  7  7  7  7  7  7  7  7  7  7 -1  7  7  7  7  7  7  7\n",
      "  3  7  7  7  7  7  7  7  5  7  7  7  7  7  7  7  7  7  7  7  7 -1  7  7\n",
      "  7  7 -1  7  5  7 -1  3  7 -1  7  7  7  7  7  7  7  7  7  7  7 -1  7  7\n",
      "  7 -1  3  3  7 -1  7 -1  0 -1  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  5  7  7  7  7  7  7  7  7  7  7  7  7  7  7 -1\n",
      " -1  7  7  3 -1  7  3  7  7  4  7 -1  7  7  7  7  3  7  7  7  7  7  7 -1\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7 -1  7  7 -1  7  5  7  7  7\n",
      "  3  7  7  7  7 -1  3  7 -1 -1 -1  3  3 -1  7  7  7  7  7  2 -1  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7 -1  3  7  7  7  7  7  7  7  7  7  7\n",
      " -1  7  7  7  7  7  7 -1  7  3  7  7  7  7  7  7  7 -1 -1  7 -1  7 -1  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  3  7  3 -1  7  7  7  7  3 -1  7  7 -1\n",
      "  7  7  7 -1  7  7  7 -1  7  3  7  7  7  7  7  7  3  7  7 -1  7  7  3  7\n",
      "  3  7  7  7  7  3  7  7 -1  7  7  7  3  7  7  7  7  7  7  7  7 -1  7  7\n",
      "  7  7 -1  7  3  7  7  7  7  5  7 -1  7 -1 -1  7 -1  7  7  3  7  7 -1  7\n",
      "  7  3  3  7  7  7 -1 -1  7  7  7  7  7  7  7  7  7  6  7  7  7  7  7  7\n",
      "  3  7  7  3  7  7  7  7  7  7  7  7  7  3  7  7  7 -1 -1  2  3 -1 -1  7\n",
      "  7 -1  2  7  7  7  7  7  7  3  7  3  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7 -1  2  7  3  7  7  7  7 -1 -1  5  3  7  7  7  7  7  7  7  7  7 -1\n",
      " -1  3  7  7  7  7  7  7  7  7  7  7  7  7  2  7 -1  3  7  7  7  7  7  7\n",
      "  7  2  7  7 -1  7  7  7  7  7  7  7  7  7  5  7  7  7  7  7  7 -1  7  6\n",
      "  7  7  7  7  7  7  3  7  7  7 -1  7  7  3  7  7 -1  7 -1  3  7  7  7  7\n",
      "  7  7  3  7  7  2  7  7  7  7  7  7  7 -1  7  3  7 -1  7  7  7  7 -1  7\n",
      " -1 -1 -1  7  7  7  7  7  7  7  7  7  7  7  7  7  3  3  7  7  3  5  7  7\n",
      "  3  7  7 -1  7  3  7  7  2  7  7  7  7  7  7  7  7  7  3  7 -1  7  7  7\n",
      "  7  7  7  7  7  7  7  7  3  7  3  7  7  5  3  7  7  3  7 -1  7  7  7  3\n",
      "  7  7  7  7  7 -1  7 -1  7  7  7  7  7  7  7 -1  7  7  7  7 -1  7  3 -1\n",
      "  7  7  7  7  7  7  3  7  7  7  7 -1  7 -1  3  7  7 -1  7  3 -1 -1 -1  7\n",
      "  7  7  7  7  7  7 -1  7  3  7  3  7 -1  7  7  7  7 -1  7  7  7 -1  7  7\n",
      "  7 -1  7  7  7  3  7  7  7  7  7 -1  7  7  7  7  7 -1 -1  7  7  7  7  7\n",
      "  7  7  7  7 -1 -1  7  7  7  7  7  7  7  7  7  7 -1  7  7  7  7  5  7  3\n",
      "  7  7  7  7  7  7  7  7  3  7  3  3  3  7  7 -1 -1  3 -1  7  7  7  7  7\n",
      "  7  7  7  7  7  7 -1  7  7  7  7  7  7  7  7  7  7  3 -1  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  3  7  7  7  7  7  7  2  3  7  7  7  7  7\n",
      "  7  7  7  7 -1  0  7  7  7  7  7  7  7  7 -1  7  7  7  7  7  7  7  7  7\n",
      "  2  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7 -1  7  7  7  7 -1  7  7  7  7  7  7  7  7 -1  7  7  7  7  2  7\n",
      "  7 -1  7  7  7  7  7 -1  7  7  6  7  2  2  7  7  7  7  7  3 -1  7  7  7\n",
      "  7  7  7  7  3  7 -1  7  3  3  7  3  7  7  7  7  7  7  7  7 -1  2  2  2\n",
      "  2  2  5  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  3  2  3  2  5  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  5  2  2  5  2  2\n",
      "  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5\n",
      "  5  2  2  6  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  7\n",
      "  7  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  3  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  5\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  7  5  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  5  2  2  2  3  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2  5\n",
      "  2  2  2  2  2  2  0  2  2  2  2  2  2  2  2  2  3  5  5  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  5  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2 -1  5  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  5  5\n",
      "  2  2  2  2  2  2  2  6  2  2  2  2  2  2  2  2  2  2  2  2  5  5  5  5\n",
      " -1  5  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  7  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2 -1  2  2  2  5  2  2 -1  2  2  2\n",
      "  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2 -1  2\n",
      " -1  2  2  2  2  2  2  2  2  2  2  2  2  2  3  2  2  2 -1  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  5  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  5  2  2  2  2  2\n",
      "  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  1  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  5  2  5  5  2  2  5  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  5  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  5  5  5  5  2  2  2  2  2  2  2  2  2  2  2  2  2  3  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  5  2  5  2  2  2\n",
      "  5  2  2  2 -1  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  7  2  2\n",
      "  2  2  2  2  5  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  5\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  3  2  2  2  2  2  2  2  2  2  2\n",
      "  2  3  3  2  2  2  2  1  2  5  2  2 -1  2  2  2  2  2  2  2  2 -1  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2\n",
      "  2  3  2  3  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  6  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  5  5  2  2  5  2  2  2 -1  6  2  2  2  5  2  2\n",
      "  2  5  2  2  2  2  5  2  2  2  2  2 -1  2 -1  2  3 -1  2  2  2  2  2  2\n",
      "  6  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  6  2  2  2  2  2\n",
      "  2  2  2  2  2  5  5  5  2  2  3  2  5  5  2  2  2  2  2  2  2  2  2  2\n",
      " -1  5 -1  2  2  2  2  2  2  2  2  2  2  5  2  5  2  2  2  2  2  2  2  2\n",
      "  7  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  6  2  2\n",
      "  5  2  2  2  2 -1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2\n",
      "  2  3  2  2 -1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2 -1  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  6  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5 -1\n",
      "  5  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2 -1  2  2  2\n",
      "  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  3  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  3  2  2  2  2  2  7  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      " -1  2  2  2 -1  2 -1  6  2  2  5  2  2  2  5  5  2 -1  6  2 -1 -1 -1  2\n",
      "  2  3  2  4 -1  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  3  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  6  2  3  2  2  2  2  2  2  2  2  2 -1  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  5  2  2  2\n",
      "  2  2  2  2  2  2  6  2  2  2  2  5  2  2  2  2  2  5  2  2  2  2  2  2\n",
      "  2  2  2  2  2  5  2  3  2  2  2  5 -1  2  2  2  2  2  3  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2 -1  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  5  2  2  2  2  5  2  2  2  2  2  5  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  0  5\n",
      "  6  0  0  2  5  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  5  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2\n",
      "  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2 -1  5  5 -1  2  2  2\n",
      "  2  2  2  2  2 -1 -1 -1 -1  2  5  5  3 -1  3  2 -1  2  5  3  5  5  2  5\n",
      " -1  2 -1 -1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2\n",
      "  2  2  2  2  2  2  2  5 -1  5  5  3  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  1  2  2 -1 -1 -1 -1  2  5\n",
      "  2  2  2  2  2  2  2  2  2 -1 -1 -1  5  2  2  2  2  2  5  2 -1  3  2  2\n",
      "  2  2  2  2  2  2  2  2  2  3  6  2  2  2  2  2  2  2  5  5  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  7  2  2  2\n",
      "  2  3  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2\n",
      "  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  5  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  5  5  5  5  5 -1  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  5  2 -1  2  2  2  5 -1  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  5  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  6 -1  5 -1  7  5  2  2  2  2  2  2  2\n",
      " -1  5 -1 -1  5 -1  5 -1  2 -1  5  2  2  5  2  2  2  2  5  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  5  2  2  2  2  5  2  2  2  5  2  2  2  2 -1  5 -1  2\n",
      " -1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2 -1  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  5  3  2  2  2  2  2  2  3  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2\n",
      "  2  2  2  2  2  2  2  2  2  5  2  5  2  2  2  5  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  5  5  2  2  5  2  5  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5\n",
      "  2  2  2  2  2  2  2  2  2 -1 -1 -1  5  2  3  5  3 -1 -1 -1 -1 -1  2 -1\n",
      "  3 -1 -1 -1  5 -1  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2 -1 -1  2  2\n",
      "  2  2 -1  2  2  5  3  2  2  2  2  3  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  5  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  5  3 -1 -1  5  2 -1  5 -1  5  5 -1 -1\n",
      "  5 -1  2  2  2  2  2  2  2  2  2  2  2 -1 -1  5 -1 -1 -1 -1 -1 -1  5  5\n",
      " -1 -1 -1  2  5 -1  5 -1  5 -1  3 -1 -1  2  2  5  6 -1 -1  3  2 -1 -1 -1\n",
      " -1  7  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5 -1\n",
      "  2  2  2  2  2  2  2  2  5  2  5 -1  2  2  2  2  2 -1  2  2 -1 -1 -1 -1\n",
      "  4 -1  5 -1  5  5 -1  6 -1  2  7  2  2  2  5  2  2  5 -1  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  5  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  3  3\n",
      "  3 -1  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  0  3  3  3  3\n",
      "  3  3 -1 -1  3  3 -1  3  3  3  3  3  3  3  3  3  3 -1  3  7 -1  3 -1 -1\n",
      "  3  3  3  3 -1  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3 -1  3  3  3 -1  3  3  7  7  3  3  7  3  3  3  3  3 -1  3 -1  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  6  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3 -1  3  3  3  3  0  3 -1  3  3  7  7  3  3 -1  3  3  3 -1  3 -1\n",
      "  3  3  3  3 -1 -1  5  3  3  3  3  3  3  3  3 -1  3  3 -1  3  3  3  3  3\n",
      "  3 -1 -1  3  3 -1 -1  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  7  3  3  3 -1 -1  3  7  3  3  3 -1  3  4  3  3 -1  3  3\n",
      "  3 -1  3  7  3  2  3  3  3  3  3  3  3  3 -1  3  7  3  3  3  3  3 -1  3\n",
      "  3  3  3  1  3  3 -1 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1\n",
      "  3  3 -1  3  7  0  3  3  3 -1  3  3 -1  3  3  3  5 -1  3  3  3  3  3  7\n",
      "  3  3  3  3  3  3  3  7  7  3 -1  3  3 -1  3 -1  7  3 -1  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  6 -1  7  3  3  3  7  3  3 -1  3  3  3\n",
      "  3 -1  3  3  3  3  3  3  3  3  3  3 -1  3 -1  3  3  3  3  3 -1  0  3  3\n",
      "  3 -1 -1  3  3 -1  7  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3\n",
      "  6 -1  3  3  3  3 -1  3  3  1 -1  3 -1  3  3  3  3  7  3  7  7  3 -1  3\n",
      " -1 -1  7  3 -1  3  3  3  3  3  3 -1  3  3 -1  3  3 -1  7  3  3  3  3  3\n",
      " -1  3  3  3  3  3  3  3  3  3  3  3  3 -1  3 -1  3  3  3  7  3  3  2  3\n",
      "  7  5 -1  3  5  3  3 -1  3  3  3  5  3  3  3  2  3  0  3  3  3  5  3  3\n",
      "  3  3  3  3  3  3  7  3  3  3  3  3  3 -1 -1  3  1 -1  3  3 -1  3 -1  3\n",
      "  3  7  3 -1  3  3  3  3  3 -1  3  3  3 -1  3  7  3  3  3  3  3 -1  3  3\n",
      "  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7  3  1  3\n",
      "  3  3  3  6  3  3  3  3  3  3  3  3  3  5  3  3  3  6  3  3  3  3  3  7\n",
      "  3  7  3  3  3  3  3  3  3 -1 -1  5  3  3  3 -1 -1  3  6 -1  3  5  3  3\n",
      "  3  3  3 -1  3  3  3  7  3 -1  3  3  3  3  3  3  3  2  3 -1  3  7  3  3\n",
      "  3 -1  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  6  3  3  3  3  7  3  7  2  3  3  7  3  3\n",
      "  3  7  3  3  7  3  3 -1  3  2  3  7 -1  3  3  3  3  3  3 -1  3 -1  3  3\n",
      "  7 -1  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3 -1  3  3  3  3  3\n",
      " -1  3  3  3 -1  3  3  3  3 -1  3  3  3  3  3  3  6  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  7  3  3  3  3  3  3  3 -1  3  3  3 -1  3\n",
      "  3  3  3  3  3  3  3  7  3  3 -1 -1  7  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3 -1  3  3  3  3  7  3  3  3 -1  3  5  3  3  3  3  2  3  3  5\n",
      "  3  3  3  3  3  3  7  3  3  3  3  3  7  3 -1  2  3 -1  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  2  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      " -1  3 -1  3  3 -1  3  3 -1  2  6  3  3  3  3  5  3  3  3  1  3 -1  2  3\n",
      "  3 -1  3  2  3  3 -1  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3\n",
      "  5  3  3  3  3  3  6  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1 -1  3  3  3  3\n",
      " -1  3  3  3  3 -1  3  7 -1 -1 -1  3 -1  3  3  3  3  3  3  3 -1  3  3  3\n",
      "  3  3  3  3  3  3  3  3 -1  5  3  3  3  3  3  3  3  3  3  3  3  3  7  3\n",
      "  3  3  3  3  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3  2  3  3  3  3\n",
      "  3 -1  3  3 -1  3  3  3  3  3 -1  3  3  3  3  3  3  3  3 -1  3  3  3  7\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3 -1  3 -1  3  3  3 -1  3  3  3  3  3  3  7  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6 -1 -1  3  3  3\n",
      "  3  7  3  3  3 -1  3  3  3  3 -1  2  3  3  3  3  3  3 -1 -1 -1  3  3  3\n",
      "  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  7  6  3  3  3  3  3  3  2  3\n",
      "  3  7  3  3 -1  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3\n",
      " -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7 -1  3 -1  3  3  3\n",
      "  3  3  3  3  3 -1  3  3  3  3  7  3  5  3  3  3  3  6  3  3  3  3  3  3\n",
      "  3  3 -1  3  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3 -1\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7 -1  3  3  3  3  3\n",
      " -1  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  6  3 -1  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3 -1 -1 -1  3  3  3  3  5  3  2  3  3  0  3  3  3  5 -1\n",
      "  3  3  3  3  3  3 -1  3  3 -1 -1  3  3  7  3  3  3  3  3  3 -1  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  7\n",
      "  3  7  3 -1  0 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  7  7  3  3 -1\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  7  3  3  7  3  3  3  3 -1  3  3\n",
      "  3  3  3  3 -1  3  3  3  5  3  3  3  3  3  3  3  3  3  7  6  3  3  3  3\n",
      "  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6 -1  3  3  7\n",
      "  3  3  3  3  3  3  3  3  3  6  3  3 -1  3  3  3  7  3  3  3  3 -1 -1  3\n",
      " -1  3  3  3  3  3  3  7  3 -1  3  7  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  5  3  3  3  2  5  3 -1  6  3 -1  3  3  3  3  7  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  5  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  6  3  3  3 -1 -1  3  3  3  3  3  3  3  0  3  3  3 -1  3  3 -1  3\n",
      "  3  3  3  3  3  3  3  0  0  3  3  3  3  3  0  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3\n",
      "  3  3  3  6  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  0  3  3\n",
      " -1  3  3  3  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3 -1  3  3\n",
      "  3  7  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  7  3  3  3  3  3\n",
      "  7  3  3  3  3  3 -1  3 -1  3 -1  3  3  3  3  3  3  6  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6  3  3  3  3  7  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  5  3  3  3  3  6  3  3\n",
      "  3 -1  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3 -1  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  7  3  3\n",
      "  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  6  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  5  3  3  7  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  7\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3 -1  3  3\n",
      "  3  3  3  3  3  3 -1 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1\n",
      " -1  3  3  3  3  3  3  3  3  3  3  3  3  3  6  3  3  3  3  3  3  3  3  3\n",
      "  7  3  3  3  3  3  3  3  3  2  3  3  3 -1  3  3  3  3  7  3  6  3  3  3\n",
      "  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3 -1\n",
      "  3 -1  6  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  6  3 -1  3  3  3  3  3  3  3  3  3  5  3  3  3  7  3  3\n",
      "  3  3  3  3  3  3  3 -1  3  3  3  3  3  3 -1  3  3  3  3  3 -1  3  3  3\n",
      "  3  2  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  5  3  3  3 -1  3  3\n",
      "  3  3  3  3  7  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3 -1 -1  3  3  3  3  3  3  3  3  3 -1  1  3  3  3  3  3  3\n",
      "  3  3  3  3  2  3  3  3  3  3  3 -1  3  3  3  3 -1  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  7  3  3  3  7  3  3  3  3 -1  3  3  3  3  3  3  3\n",
      "  3  7  3  3  3 -1  7  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3\n",
      "  3  5 -1  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  6  3  3  3  3  3  3 -1  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  5  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3 -1  3  3  3  3  5  3 -1\n",
      "  3  3  3  3 -1  3  3  3  3  7  3 -1  3 -1  3  3  3  3  3  3  3  7  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6  3 -1  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  6  3 -1  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  5  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  6  3  3 -1  3  3  3  3  3  3  3 -1  5  3  3  3  3  3  3  3  3\n",
      "  7  3  3  3  3  3  3  3  3  3  3  3  3  7  3  3  3  3  3  5  3  3  3  3\n",
      "  4  3  3  3  3  6  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3\n",
      "  3 -1  3  3  3  3  3  3 -1  3 -1  6  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7  3  3  3  3  3\n",
      "  3  3  3 -1  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  6  1  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7  3  3  3  6  3 -1  2  3\n",
      "  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  6 -1\n",
      "  3  3  3 -1  3  3  3  3  3  3  4  6  3  3  3  3  3  3  5  3  3  3 -1  3\n",
      "  3  3  3  3  3 -1  3 -1  5  3  3  7  3  3  5  3  3 -1 -1  3  3  3  3  3\n",
      "  3  3 -1  3  3  3 -1  3  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  7  3  3  3 -1  3\n",
      " -1  3  3  3  3  3  3  3  7  7  3  3  3 -1  3  3  3  3  3  3  3  3  3  5\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3 -1  3  3  3  3  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3 -1  3\n",
      "  3  7  3  3  3  3  3  3  3  3 -1  3 -1  3 -1  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3 -1  3  3  3  3  3  3  3  3 -1  3  3  3  3 -1  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  6  3  7  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  7\n",
      "  7  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6  3  3  3  7  3  3\n",
      "  3  3  3  3  3  3  3 -1 -1  3  3  3  6 -1  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  6  3  3  3  3  3  3  3  3\n",
      "  3  3  7  3  3  3  3  6  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3\n",
      "  3  3 -1  3  3  3  3  3  3  3  3  3  6  3  3  3  3  3  3  3 -1  3  3  3\n",
      "  3  3  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  6  3  3  3  3  3  3  3  3  6  3  3  3  7  3  3  3  7\n",
      "  3  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6  3  3  3  3  3  3  3  3\n",
      "  3 -1  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  2  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6  3\n",
      "  3  6  3  3  3  3  3  3  7  3  3  3  3  3  3  0  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  6  3  3  3  3  2  3  3 -1 -1 -1 -1  3  3  3  3  3  7  3  3\n",
      " -1  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3 -1  3  3  3  3  3  3 -1  3  3  3  3  6  3  3  3  3\n",
      "  3 -1  3  3  6  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  5  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7\n",
      "  3  3  6  3  3  3  3  3  3  3  3  7  3  3  3 -1  7  3  3  3 -1  3  3  3\n",
      "  3  3  5 -1  3  3  3  3 -1  3  3  3  3 -1  3  3  3  3  3  3  3 -1  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3\n",
      "  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3\n",
      "  3  3  3  5  3  3 -1  3  3  3  3  3 -1  3 -1  3  3  3  3  3  3  3  3  3\n",
      "  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3 -1  3  3  3  3 -1  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  5  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3 -1\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  5 -1\n",
      "  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  7  3  3  3  3  7\n",
      "  3  3  3  3  3  3  3  5  3  6  3  3 -1  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  5  3  3  3  3  3  3  2  3  3  3\n",
      "  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3 -1  6  3  3  3  3  3  3  3  3  3  3  3  3  3  5  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  7  5  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3 -1  3  3  3\n",
      "  3 -1  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3\n",
      "  6  3  3  3  3  3  3  3  3  3 -1  3 -1  3 -1  3  3  3  3  3  3  3 -1  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3\n",
      "  2  3  3  3  3  3  3  3  3  3 -1  3  3  3  3 -1  3  3  3  3  3  3  3  7\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7\n",
      "  3 -1  3  3  3 -1  3  3  3  3 -1  3  3  3  3 -1  3  3  3  3  3  3  3  3\n",
      "  3  3  3  2  3  3  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3  7 -1  3\n",
      "  3  3  3  3  3  3 -1  3 -1  3  3  3  3  3  3  3  5  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  5  3 -1  3  3  3  3  3  3 -1  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  7  3  3  3  3  3  3  3  5  3  3  3  3  3  2  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3 -1  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      " -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6  7  3  3  3  7  3\n",
      "  3  3  3  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3  3  7 -1  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  6  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3 -1  3  3  3  3  3  3  3  7  3  3  3  3  3  3  7  3  3  3  0 -1\n",
      "  3  3  7  1  7  0  3  3  3  3  3  3  7  0  7  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  5  3 -1  3  3  3  3  3  7  3  3  3  3  3  6  3  3  3  3  6  3  6\n",
      "  3  3  3  3  3  2  3  3  7 -1  3  3  3  2  6  5  5  2  5  3  3  3  5  5\n",
      "  2  3  3  3  3  3  3  3  3 -1  7  3  3  3  3  3  3  3  3  3  3  3  5 -1\n",
      "  3  3  5  3  3 -1 -1 -1  2 -1 -1 -1  3  3  5 -1  3  5  5  0  3  3 -1  2]\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ 4ï¸âƒ£ OOD ë°ì´í„° ë¡œë“œ & ì „ì²˜ë¦¬ (MFCC íŠ¹ì§• ì‚¬ìš©)\n",
    "ood_X_test = df_combined2.iloc[:, -50:]  # OOD ë°ì´í„°ì˜ MFCC 13ê°œ ì»¬ëŸ¼ ì‚¬ìš©\n",
    "\n",
    "# ğŸ“Œ 5ï¸âƒ£ Softmax ê¸°ë°˜ OOD íƒì§€ í•¨ìˆ˜\n",
    "def predict_with_ood_detection(model2, X, threshold=0.6):\n",
    "    probs = model2.predict_proba(X)  # Softmax í™•ë¥  ì¶œë ¥\n",
    "    max_probs = np.max(probs, axis=1)  # ê°€ì¥ ë†’ì€ í™•ë¥  ê°’\n",
    "    preds = np.argmax(probs, axis=1)  # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤\n",
    "\n",
    "    # íŠ¹ì • í™•ë¥ (threshold) ì´í•˜ì´ë©´ \"ê¸°íƒ€ ì†ŒìŒ\"(-1)ìœ¼ë¡œ ë³€ê²½\n",
    "    final_preds = np.where(max_probs < threshold, -1, preds)\n",
    "    \n",
    "    return final_preds\n",
    "\n",
    "# ğŸ“Œ 6ï¸âƒ£ OOD íƒì§€ ì ìš© (í…ŒìŠ¤íŠ¸ ë°ì´í„° & ê¸°íƒ€ ì†ŒìŒ ë°ì´í„°)\n",
    "#y_pred_test = predict_with_ood_detection(model, X_test, threshold=0.8)\n",
    "y_pred_ood = predict_with_ood_detection(model2, ood_X_test, threshold=0.8)\n",
    "\n",
    "# NumPy ë°°ì—´ ì¶œë ¥ ì˜µì…˜ ë³€ê²½ (ìƒëµ ì—†ì´ ì¶œë ¥)\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# ğŸ“Œ 7ï¸âƒ£ ê²°ê³¼ ì¶œë ¥\n",
    "#print(\"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ê²°ê³¼:\", y_pred_test)\n",
    "print(\"âœ… OOD (ê¸°íƒ€ ì†ŒìŒ) ì˜ˆì¸¡ ê²°ê³¼ (Softmax ê¸°ë°˜ í•„í„°ë§):\", y_pred_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c80c43-742f-40c3-a73d-9112fd416a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(ml_env_python3.6)",
   "language": "python",
   "name": "ml_env_python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
