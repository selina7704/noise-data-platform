import os
import shutil
import librosa
import numpy as np
import tensorflow as tf 
import streamlit as st
import io
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from fastapi import Request
from tensorflow.keras.models import load_model

app = FastAPI()

# GPU ë¹„í™œì„±í™” (CPUë¡œë§Œ ì‹¤í–‰)
tf.config.set_visible_devices([], 'GPU')

# ëª¨ë¸ ë¡œë“œ 
# model = tf.keras.models.load_model('../ES/cnn_model_6classfication.h5')  #ë ˆì´ë¸” 6ê°œ
model = tf.keras.models.load_model('../ES/resnet_model_mfcc50.h5') #ë ˆì´ë¸” 5ê°œ 
        

# ê±°ë¦¬ ë° ë°©í–¥ ë¶„ì„ í•¨ìˆ˜
SPL_REFERENCE = 20e-6  # SPL ê¸°ì¤€ ì°¸ì¡° ê°’ (ë³´í†µ 20uPa, ê³µê¸° ì¤‘ ì†Œë¦¬ì˜ ê¸°ì¤€)
DB_REFERENCE = {
    'ì´ë¥œì°¨ê²½ì ': 85, 
    'ì´ë¥œì°¨ì£¼í–‰ìŒ': 75, 
    'ì°¨ëŸ‰ê²½ì ': 85, 
    'ì°¨ëŸ‰ì‚¬ì´ë Œ': 90, 
    'ì°¨ëŸ‰ì£¼í–‰ìŒ': 80,
}

def analyze_audio(file_path, noise_type):
    try:
        y, sr = librosa.load(file_path, sr=None, mono=False)

        # ëª¨ë…¸/ìŠ¤í…Œë ˆì˜¤ íŒë³„
        is_stereo = len(y.shape) == 2 and y.shape[0] == 2

        # RMS SPL(í‰ê·  ë°ì‹œë²¨) ê³„ì‚°
        if is_stereo:
            left_channel = y[0]
            right_channel = y[1]
            rms_total = np.sqrt(np.mean((left_channel + right_channel) ** 2)) / 2
        else:
            rms_total = np.sqrt(np.mean(y ** 2))

        rms_spl = 20 * np.log10(rms_total / SPL_REFERENCE + 1e-6)  # RMS SPL ë³€í™˜

        # ì†ŒìŒ ìœ í˜•ì— ë”°ë¥¸ SPL ê³„ì‚° ë° ê±°ë¦¬ ì¶”ì •
        db_ref = DB_REFERENCE.get(noise_type, 85)
        estimated_distance = 1 * (10 ** ((db_ref - rms_spl) / 20))
        
        # ê±°ë¦¬ ë° ë°©í–¥ ë¶„ì„
        direction = "ì¤‘ì•™" if is_stereo else None  # ìŠ¤í…Œë ˆì˜¤ì—ì„œë§Œ ë°©í–¥ ì •ë³´ ì œê³µ
        distance_alert = "ì•ŒëŒ ì—†ìŒ" if estimated_distance > 10 else "ğŸš¨ ìœ„í—˜ ì†ŒìŒ!"

        return estimated_distance, direction, distance_alert
    except Exception as e:
        return None, None, None

@app.get("/")
def read_root():
    return {"message": "ì†ŒìŒ ë¶„ë¥˜ ëª¨ë¸ API"}


@app.post("/predict/")
async def predict(file: UploadFile = File(...)):

    file_bytes = await file.read() # ì—…ë¡œë“œëœ íŒŒì¼ì„ ë°”ì´íŠ¸ë¡œ ì½ì–´ì˜¤ê¸°

    # ë””ë²„ê¹…
    print(f"íŒŒì¼ ì´ë¦„: {file.filename}")

    # BytesIOë¡œ ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ íŒŒì¼ì²˜ëŸ¼ ì½ê¸°
    audio_data = librosa.load(io.BytesIO(file_bytes), sr=22050)[0]
    mfccs = librosa.feature.mfcc(y=audio_data, sr=22050, n_mfcc=50)
    features = np.mean(mfccs, axis=1)

    # ëª¨ë¸ ì˜ˆì¸¡
    prediction = model.predict(np.array([features]))  
    predicted_label = np.argmax(prediction)  

    # ì†ŒìŒ ì¢…ë¥˜ ë¼ë²¨
    # noise_labels = ['ì´ë¥œì°¨ê²½ì ', 'ì´ë¥œì°¨ì£¼í–‰ìŒ', 'ì°¨ëŸ‰ê²½ì ', 'ì°¨ëŸ‰ì‚¬ì´ë Œ', 'ì°¨ëŸ‰ì£¼í–‰ìŒ', 'ê¸°íƒ€ì†ŒìŒ']
    noise_labels = ['ì´ë¥œì°¨ê²½ì ', 'ì´ë¥œì°¨ì£¼í–‰ìŒ', 'ì°¨ëŸ‰ê²½ì ', 'ì°¨ëŸ‰ì‚¬ì´ë Œ', 'ì°¨ëŸ‰ì£¼í–‰ìŒ']
    # detected_noise = noise_labels[predicted_label]
    if predicted_label < len(noise_labels):
        detected_noise = noise_labels[predicted_label]
    else:
        detected_noise = "ì•Œ ìˆ˜ ì—†ëŠ” ì†ŒìŒ"  # ì˜ˆì™¸ ì²˜ë¦¬

    # ê±°ë¦¬ ë° ë°©í–¥ ë¶„ì„
    # ì†ŒìŒ íŒŒì¼ì„ ì„ì‹œë¡œ ì €ì¥ í›„ ë¶„ì„
    temp_file_path = f"/tmp/{file.filename}"
    with open(temp_file_path, "wb") as f:
        f.write(file_bytes)

    estimated_distance, direction, distance_alert  = analyze_audio(temp_file_path, detected_noise)
   

    print(f"ì˜ˆì¸¡ëœ ì†ŒìŒ ìœ í˜•: {detected_noise}")  # í„°ë¯¸ë„ì— ì¶œë ¥

    # ì˜ˆì¸¡ ê²°ê³¼ ë°˜í™˜
    response = {
        "prediction": prediction,
        "estimated_distance": estimated_distance,
        "direction": direction,
        "distance_alert": distance_alert
    }
    
    # ì‘ë‹µì„ jsonable_encoderë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ë ¬í™”í•˜ì—¬ ë°˜í™˜
    return response