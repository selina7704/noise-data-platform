import streamlit as st
import requests
import numpy as np
import pandas as pd
import os
import time
import tensorflow as tf
from tensorflow.keras.models import load_model, Model
from tensorflow.keras.layers import Dense
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
import seaborn as sns
import matplotlib.pyplot as plt
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# FastAPI ì„œë²„ ì£¼ì†Œ
FASTAPI_URL = "http://localhost:8006/predict/"

# ì €ì¥ ë””ë ‰í† ë¦¬
upload_folder = "uploads"
audio_save_path = "recorded_audio"
os.makedirs(upload_folder, exist_ok=True)
os.makedirs(audio_save_path, exist_ok=True)

# CSVìš© ì „ì—­ ë³€ìˆ˜ (ì£¼í”¼í„° ì½”ë“œ ë°˜ì˜)
MODEL = None
LOGITS_MODEL = None
ENERGY_THRESHOLD = None  # ë™ì  ê³„ì‚°
CONFIDENCE_THRESHOLD = 0.99  # ì£¼í”¼í„° ê°’
TEMPERATURE = 1.0
MEAN_ENERGY_IND = -15.3398  # ì´ˆê¸°ê°’
STD_ENERGY_IND = 8.2265     # ì´ˆê¸°ê°’

# ë¼ë²¨ ì •ì˜
label_dict = {'ì´ë¥œì°¨ê²½ì ': 0, 'ì´ë¥œì°¨ì£¼í–‰ìŒ': 1, 'ì°¨ëŸ‰ê²½ì ': 2, 'ì°¨ëŸ‰ì‚¬ì´ë Œ': 3, 'ì°¨ëŸ‰ì£¼í–‰ìŒ': 4, 'ê¸°íƒ€ì†ŒìŒ': 5}
reverse_label_dict = {v: k for k, v in label_dict.items()}
english_labels = ['Motorcycle Horn', 'Motorcycle Running Sound', 'Vehicle Horn', 'Vehicle Siren', 'Vehicle Driving', 'Other Noise']
unknown_label_index = label_dict['ê¸°íƒ€ì†ŒìŒ']

# Eager Execution í™œì„±í™”
tf.config.run_functions_eagerly(True)

# ëª¨ë¸ ì´ˆê¸°í™” (CSVìš©)
def initialize_models(model_path='resnet_model_modified_v6.h5'):
    global MODEL, LOGITS_MODEL
    if MODEL is None:
        MODEL = load_model(model_path)
        last_layer = MODEL.layers[-1]
        if last_layer.get_config().get("activation") == "softmax":
            logits = Model(inputs=MODEL.input, outputs=MODEL.layers[-2].output)
            new_dense = Dense(last_layer.units, activation=None, name='logits')(logits.output)
            LOGITS_MODEL = Model(inputs=MODEL.input, outputs=new_dense)
            LOGITS_MODEL.layers[-1].set_weights(last_layer.get_weights())
        else:
            LOGITS_MODEL = MODEL
        logging.info("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ for Streamlit")

def compute_energy(logits, T=TEMPERATURE):
    exp_vals = np.exp(logits / T)
    sum_exp = np.sum(exp_vals, axis=1) + 1e-9
    return -T * np.log(sum_exp)

def validate_mfcc_data(df):
    mfcc_columns = [f'mfcc_{i}' for i in range(1, 51)]
    if not all(col in df.columns for col in mfcc_columns):
        raise ValueError("MFCC ì—´ì´ ëˆ„ë½ë¨")
    mfcc_data = df[mfcc_columns].values
    if mfcc_data.shape[0] == 0:
        raise ValueError("ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŒ")
    if np.any(np.isnan(mfcc_data)) or np.any(np.isinf(mfcc_data)):
        raise ValueError("MFCC ë°ì´í„°ì— NaN ë˜ëŠ” Inf ê°’ í¬í•¨")
    return mfcc_data.reshape(-1, 50, 1)

def update_energy_stats(energy_scores, preds, window_size=1000, max_std_dev=20.0):
    global MEAN_ENERGY_IND, STD_ENERGY_IND
    if not hasattr(update_energy_stats, 'buffer'):
        update_energy_stats.buffer = []

    ind_scores = energy_scores[preds != unknown_label_index]
    if len(ind_scores) > 0:
        update_energy_stats.buffer.extend(ind_scores)
        if len(update_energy_stats.buffer) > window_size:
            update_energy_stats.buffer = update_energy_stats.buffer[-window_size:]
        
        if len(update_energy_stats.buffer) >= 2:
            new_mean = np.mean(update_energy_stats.buffer)
            new_std = np.std(update_energy_stats.buffer)
            if new_std <= max_std_dev and not np.isnan(new_std):
                MEAN_ENERGY_IND = new_mean
                STD_ENERGY_IND = max(new_std, 1e-6)
                logging.info(f"Updated MEAN_ENERGY_IND: {MEAN_ENERGY_IND:.4f}, STD_ENERGY_IND: {STD_ENERGY_IND:.4f}")

def predict_samples(df):
    initialize_models()
    X = validate_mfcc_data(df)
    y_true = df['ood_label'].map(label_dict).fillna(5).astype(int).values

    global ENERGY_THRESHOLD
    if ENERGY_THRESHOLD is None:
        logits_temp = LOGITS_MODEL.predict(X, verbose=0)
        energy_scores_temp = compute_energy(logits_temp)
        softmax_probs_temp = np.exp(logits_temp) / np.sum(np.exp(logits_temp), axis=1, keepdims=True)
        threshold_candidates = np.linspace(energy_scores_temp.min(), energy_scores_temp.max(), 100)
        best_f1 = -1
        for thr in threshold_candidates:
            temp_preds = np.where((np.max(softmax_probs_temp, axis=1) < CONFIDENCE_THRESHOLD) & 
                                  (energy_scores_temp > thr), unknown_label_index, np.argmax(softmax_probs_temp, axis=1))
            f1 = f1_score(y_true, temp_preds, labels=[unknown_label_index], average='weighted', zero_division=0)
            if f1 > best_f1:
                best_f1 = f1
                ENERGY_THRESHOLD = thr
        logging.info(f"ìµœì  Energy Threshold: {ENERGY_THRESHOLD:.4f}, F1-score: {best_f1:.4f}")
    else:
        logging.info(f"ê¸°ì¡´ ENERGY_THRESHOLD ì‚¬ìš©: {ENERGY_THRESHOLD}")

    logits = LOGITS_MODEL.predict(X, verbose=0)
    energy_scores = compute_energy(logits)
    softmax_probs = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)
    max_probs = np.max(softmax_probs, axis=1)
    basic_preds = np.argmax(softmax_probs, axis=1)
    z_scores = (energy_scores - MEAN_ENERGY_IND) / STD_ENERGY_IND

    final_preds = np.where((max_probs < CONFIDENCE_THRESHOLD) & 
                           (energy_scores > ENERGY_THRESHOLD),
                           unknown_label_index, basic_preds)

    update_energy_stats(energy_scores, final_preds)
    logging.info(f"Energy ë²”ìœ„: min={np.min(energy_scores):.4f}, max={np.max(energy_scores):.4f}, mean={np.mean(energy_scores):.4f}")
    
    return final_preds

def main():
    st.title("ì†ŒìŒ ë¶„ë¥˜ê¸°")

    # ì‹¤ì‹œê°„ ë…¹ìŒ
    audio_value = st.audio_input("ìŒì„±ì„ ë…¹ìŒí•˜ì„¸ìš”!")
    if audio_value:
        st.audio(audio_value, format='audio/wav')
        file_path = os.path.join(audio_save_path, "recorded_audio.wav")
        with open(file_path, "wb") as f:
            f.write(audio_value.getvalue())
        st.success(f"ë…¹ìŒëœ ì˜¤ë””ì˜¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {file_path}")

        if st.button("ë…¹ìŒ ì˜ˆì¸¡í•˜ê¸°"):
            start_time = time.time()
            files = {"file": ("recorded_audio.wav", audio_value.getvalue(), "audio/wav")}
            response = requests.post(FASTAPI_URL, files=files)
            elapsed_time = time.time() - start_time

            if response.status_code == 200:
                prediction = response.json()
                if "error" in prediction:
                    st.error("ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ! ğŸš¨")
                else:
                    st.success("ë¶„ì„ ì™„ë£Œ âœ…")
                    st.write(f"**ì˜ˆì¸¡ëœ ì†ŒìŒ ìœ í˜•:** {prediction.get('prediction', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                    st.write(f"**ì†ŒìŒ í¬ê¸° (dB):** {prediction.get('spl', 'N/A')} dB")
                    st.write(f"**ì¶”ì • ê±°ë¦¬:** {prediction.get('estimated_distance', 'N/A')} ë¯¸í„°")
                    st.write(f"**ë°©í–¥:** {prediction.get('direction', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                    st.write(f"**ì‹ ë¢°ë„:** {prediction.get('confidence', 'N/A')}")
                    st.write(f"â±ï¸ ì˜ˆì¸¡ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
            else:
                st.error("ì„œë²„ì™€ì˜ í†µì‹  ì˜¤ë¥˜ ë°œìƒ! âŒ")

    # WAV íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["wav"])
    if uploaded_file is not None:
        st.audio(uploaded_file, format='audio/wav')
        st.write(f"íŒŒì¼ ì´ë¦„: {uploaded_file.name}")

        upload_path = os.path.join(upload_folder, uploaded_file.name)
        with open(upload_path, "wb") as f:
            f.write(uploaded_file.getvalue())
        st.success(f"ğŸ“‚ ì—…ë¡œë“œëœ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {upload_path}")

        if st.button('ì—…ë¡œë“œ ì˜ˆì¸¡í•˜ê¸°'):
            start_time = time.time()
            files = {"file": (uploaded_file.name, uploaded_file.getvalue(), "audio/wav")}
            response = requests.post(FASTAPI_URL, files=files)
            elapsed_time = time.time() - start_time

            if response.status_code == 200:
                prediction = response.json()
                if "error" in prediction:
                    st.error("ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ! ğŸš¨")
                else:
                    st.success("ë¶„ì„ ì™„ë£Œ âœ…")
                    st.write(f"**ì˜ˆì¸¡ëœ ì†ŒìŒ ìœ í˜•:** {prediction.get('prediction', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                    st.write(f"**ì†ŒìŒ í¬ê¸° (dB):** {prediction.get('spl', 'N/A')} dB")
                    st.write(f"**ì¶”ì • ê±°ë¦¬:** {prediction.get('estimated_distance', 'N/A')} ë¯¸í„°")
                    st.write(f"**ë°©í–¥:** {prediction.get('direction', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                    st.write(f"**ì‹ ë¢°ë„:** {prediction.get('confidence', 'N/A')}")
                    st.write(f"â±ï¸ ì˜ˆì¸¡ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
            else:
                st.error("ì„œë²„ì™€ì˜ í†µì‹  ì˜¤ë¥˜ ë°œìƒ! âŒ")

    # CSV ì—…ë¡œë“œ ë° í‰ê°€
    st.title("ì†ŒìŒ ë¶„ë¥˜ ì„±ëŠ¥ í‰ê°€")
    uploaded_csv = st.file_uploader("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["csv"])
    if uploaded_csv is not None:
        try:
            df = pd.read_csv(uploaded_csv)
            st.write("ğŸ“Œ **ì—…ë¡œë“œëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°**:")
            st.dataframe(df.head())

            if st.button("ì˜ˆì¸¡ ì‹¤í–‰"):
                predicted_labels = predict_samples(df)
                df['predicted_label'] = [reverse_label_dict[label] for label in predicted_labels]

                st.write("ğŸ¯ **ì˜ˆì¸¡ ê²°ê³¼**:")
                st.write(df.head())

                y_true = df['ood_label'].map(label_dict).fillna(5).astype(int).values
                y_pred = predicted_labels

                report = classification_report(y_true, y_pred, target_names=english_labels, output_dict=True)
                cm = confusion_matrix(y_true, y_pred, labels=list(label_dict.values()))
                overall_accuracy = accuracy_score(y_true, y_pred)

                st.subheader("í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ ê²°ê³¼")
                metrics_df = pd.DataFrame({
                    'Class': english_labels,
                    'Precision': [report[label]['precision'] for label in english_labels],
                    'Recall': [report[label]['recall'] for label in english_labels],
                    'F1-Score': [report[label]['f1-score'] for label in english_labels],
                    'Support': [report[label]['support'] for label in english_labels]
                })
                st.table(metrics_df.round(4))
                st.write(f"Overall Accuracy: {overall_accuracy:.4f}")

                st.subheader("Confusion Matrix")
                plt.figure(figsize=(8, 6))
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                            xticklabels=english_labels, yticklabels=english_labels)
                plt.xlabel("Predicted")
                plt.ylabel("Actual")
                plt.title("Confusion Matrix")
                st.pyplot(plt)

                st.write(f"ìµœì¢… ê°’: ENERGY_THRESHOLD={ENERGY_THRESHOLD:.4f}, MEAN_ENERGY_IND={MEAN_ENERGY_IND:.4f}, STD_ENERGY_IND={STD_ENERGY_IND:.4f}")

                csv = df.to_csv(index=False).encode('utf-8')
                st.download_button("ğŸ“¥ ì˜ˆì¸¡ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", csv, "predictions.csv", "text/csv")
        except Exception as e:
            st.error(f"ğŸš¨ CSV ì½ê¸° ì˜¤ë¥˜: {str(e)}")

if __name__ == "__main__":
    main()